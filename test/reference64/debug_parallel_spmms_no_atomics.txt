julia> @finch begin
        CR .= 0
        for i = _
            for j = _
                for k = _
                    CR[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(CR = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            phase_start_2 = max(1, 1 + fld(A_lvl.shape[1] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                for i_7 = phase_start_2:phase_stop_2
                    B_lvl_q = B_lvl_ptr[1]
                    B_lvl_q_stop = B_lvl_ptr[1 + 1]
                    if B_lvl_q < B_lvl_q_stop
                        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                    else
                        B_lvl_i_stop = 0
                    end
                    phase_stop_3 = min(B_lvl.shape[2], B_lvl_i_stop)
                    if phase_stop_3 >= 1
                        if B_lvl_tbl2[B_lvl_q] < 1
                            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        while true
                            B_lvl_i = B_lvl_tbl2[B_lvl_q]
                            B_lvl_q_step = B_lvl_q
                            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                            end
                            if B_lvl_i < phase_stop_3
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_5 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_5 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_5
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_6 = min(B_lvl_i_2, phase_stop_5, A_lvl_i)
                                        if A_lvl_i == phase_stop_6 && B_lvl_i_2 == phase_stop_6
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_7 = min(i_7, A_lvl_i_stop_2)
                                            if phase_stop_7 >= i_7
                                                if A_lvl_tbl1[A_lvl_q] < i_7
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_7
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_9 = min(A_lvl_i_2, phase_stop_7)
                                                        if A_lvl_i_2 == phase_stop_9
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_6
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_6
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_6 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            else
                                phase_stop_14 = min(B_lvl_i, phase_stop_3)
                                if B_lvl_i == phase_stop_14
                                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_14
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_15 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_15 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_15
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_16 = min(B_lvl_i_2, A_lvl_i, phase_stop_15)
                                            if A_lvl_i == phase_stop_16 && B_lvl_i_2 == phase_stop_16
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_17 = min(i_7, A_lvl_i_stop_4)
                                                if phase_stop_17 >= i_7
                                                    if A_lvl_tbl1[A_lvl_q] < i_7
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_17
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_19 = min(A_lvl_i_4, phase_stop_17)
                                                            if A_lvl_i_4 == phase_stop_19
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_16
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_16
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_16 + 1
                                        end
                                    end
                                    B_lvl_q = B_lvl_q_step
                                end
                                break
                            end
                        end
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    for i_4 = 1:A_lvl.shape[1]
        val = Ct_lvl_2_val
        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
        B_lvl_ptr_2 = B_lvl_ptr
        B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
        B_lvl_tbl1_2 = B_lvl_tbl1
        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
        B_lvl_tbl2_2 = B_lvl_tbl2
        B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
        val_2 = B_lvl_val
        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
        A_lvl_ptr_2 = A_lvl_ptr
        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
        A_lvl_tbl1_2 = A_lvl_tbl1
        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
        A_lvl_tbl2_2 = A_lvl_tbl2
        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
        val_3 = A_lvl_val
        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
        Threads.@threads for i_5 = 1:Threads.nthreads()
                B_lvl_q = B_lvl_ptr[1]
                B_lvl_q_stop = B_lvl_ptr[1 + 1]
                if B_lvl_q < B_lvl_q_stop
                    B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                else
                    B_lvl_i_stop = 0
                end
                phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_5 + -1), Threads.nthreads()))
                phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_5, Threads.nthreads()))
                if phase_stop_2 >= phase_start_2
                    if B_lvl_tbl2[B_lvl_q] < phase_start_2
                        B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    while true
                        B_lvl_i = B_lvl_tbl2[B_lvl_q]
                        B_lvl_q_step = B_lvl_q
                        if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                            B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        if B_lvl_i < phase_stop_2
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_4, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_4
                                            if A_lvl_tbl1[A_lvl_q] < i_4
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        else
                            phase_stop_13 = min(B_lvl_i, phase_stop_2)
                            if B_lvl_i == phase_stop_13
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_4, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_4
                                                if A_lvl_tbl1[A_lvl_q] < i_4
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            end
                            break
                        end
                    end
                end
            end
        Ct_lvl_2_val = val
        B_lvl_ptr = B_lvl_ptr_2
        B_lvl_tbl1 = B_lvl_tbl1_2
        B_lvl_tbl2 = B_lvl_tbl2_2
        B_lvl_val = val_2
        A_lvl_ptr = A_lvl_ptr_2
        A_lvl_tbl1 = A_lvl_tbl1_2
        A_lvl_tbl2 = A_lvl_tbl2_2
        A_lvl_val = val_3
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        for i_6 = 1:A_lvl.shape[1]
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_6
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_6, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_6
                                            if A_lvl_tbl1[A_lvl_q] < i_6
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_6, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                        end
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_13 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_13
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                            for i_8 = 1:A_lvl.shape[1]
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_8
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_8, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_8
                                                if A_lvl_tbl1[A_lvl_q] < i_8
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_8, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    B_lvl_q = B_lvl_ptr[1]
    B_lvl_q_stop = B_lvl_ptr[1 + 1]
    if B_lvl_q < B_lvl_q_stop
        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
    else
        B_lvl_i_stop = 0
    end
    phase_stop = min(B_lvl.shape[2], B_lvl_i_stop)
    if phase_stop >= 1
        if B_lvl_tbl2[B_lvl_q] < 1
            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
        end
        while true
            B_lvl_i = B_lvl_tbl2[B_lvl_q]
            B_lvl_q_step = B_lvl_q
            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
            end
            if B_lvl_i < phase_stop
                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                val = Ct_lvl_2_val
                Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                B_lvl_tbl1_2 = B_lvl_tbl1
                B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                B_lvl_tbl2_2 = B_lvl_tbl2
                val_2 = B_lvl_val
                B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                A_lvl_ptr_2 = A_lvl_ptr
                A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                A_lvl_tbl1_2 = A_lvl_tbl1
                A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                A_lvl_tbl2_2 = A_lvl_tbl2
                A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                val_3 = A_lvl_val
                A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                Threads.@threads for i_9 = 1:Threads.nthreads()
                        phase_start_6 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_9), Threads.nthreads()))
                        phase_stop_7 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_9, Threads.nthreads()))
                        if phase_stop_7 >= phase_start_6
                            for i_12 = phase_start_6:phase_stop_7
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_12
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_8 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_8 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_8
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_9 = min(B_lvl_i_2, phase_stop_8, A_lvl_i)
                                        if A_lvl_i == phase_stop_9 && B_lvl_i_2 == phase_stop_9
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_10 = min(i_12, A_lvl_i_stop_2)
                                            if phase_stop_10 >= i_12
                                                if A_lvl_tbl1[A_lvl_q] < i_12
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_12, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_10
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_12 = min(A_lvl_i_2, phase_stop_10)
                                                        if A_lvl_i_2 == phase_stop_12
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_9
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_9
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_9 + 1
                                    end
                                end
                            end
                        end
                    end
                Ct_lvl_2_val = val
                B_lvl_tbl1 = B_lvl_tbl1_2
                B_lvl_tbl2 = B_lvl_tbl2_2
                B_lvl_val = val_2
                A_lvl_ptr = A_lvl_ptr_2
                A_lvl_tbl1 = A_lvl_tbl1_2
                A_lvl_tbl2 = A_lvl_tbl2_2
                A_lvl_val = val_3
                B_lvl_q = B_lvl_q_step
            else
                phase_stop_18 = min(B_lvl_i, phase_stop)
                if B_lvl_i == phase_stop_18
                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_18
                    val_4 = Ct_lvl_2_val
                    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                    B_lvl_tbl1_3 = B_lvl_tbl1
                    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                    B_lvl_tbl2_3 = B_lvl_tbl2
                    val_5 = B_lvl_val
                    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                    A_lvl_ptr_3 = A_lvl_ptr
                    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                    A_lvl_tbl1_3 = A_lvl_tbl1
                    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                    A_lvl_tbl2_3 = A_lvl_tbl2
                    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                    val_6 = A_lvl_val
                    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                    Threads.@threads for i_19 = 1:Threads.nthreads()
                            phase_start_21 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_19), Threads.nthreads()))
                            phase_stop_23 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_19, Threads.nthreads()))
                            if phase_stop_23 >= phase_start_21
                                for i_22 = phase_start_21:phase_stop_23
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_22
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_24 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_24 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_24
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_25 = min(B_lvl_i_2, A_lvl_i, phase_stop_24)
                                            if A_lvl_i == phase_stop_25 && B_lvl_i_2 == phase_stop_25
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_26 = min(i_22, A_lvl_i_stop_4)
                                                if phase_stop_26 >= i_22
                                                    if A_lvl_tbl1[A_lvl_q] < i_22
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_22, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_26
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_28 = min(A_lvl_i_4, phase_stop_26)
                                                            if A_lvl_i_4 == phase_stop_28
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_25
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_25
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_25 + 1
                                        end
                                    end
                                end
                            end
                        end
                    Ct_lvl_2_val = val_4
                    B_lvl_tbl1 = B_lvl_tbl1_3
                    B_lvl_tbl2 = B_lvl_tbl2_3
                    B_lvl_val = val_5
                    A_lvl_ptr = A_lvl_ptr_3
                    A_lvl_tbl1 = A_lvl_tbl1_3
                    A_lvl_tbl2 = A_lvl_tbl2_3
                    A_lvl_val = val_6
                    B_lvl_q = B_lvl_q_step
                end
                break
            end
        end
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        val_4 = Ct_lvl_2_val
                        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                        A_lvl_ptr_3 = A_lvl_ptr
                        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                        A_lvl_tbl1_3 = A_lvl_tbl1
                        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                        A_lvl_tbl2_3 = A_lvl_tbl2
                        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                        val_5 = A_lvl_val
                        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                        B_lvl_ptr_3 = B_lvl_ptr
                        B_lvl_tbl1_3 = B_lvl_tbl1
                        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                        B_lvl_tbl2_3 = B_lvl_tbl2
                        val_6 = B_lvl_val
                        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                        Threads.@threads for i_10 = 1:Threads.nthreads()
                                phase_start_7 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_10), Threads.nthreads()))
                                phase_stop_8 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_10, Threads.nthreads()))
                                if phase_stop_8 >= phase_start_7
                                    for i_13 = phase_start_7:phase_stop_8
                                        Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_13
                                        A_lvl_q = A_lvl_ptr[1]
                                        A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                        if A_lvl_q < A_lvl_q_stop
                                            A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                        else
                                            A_lvl_i_stop = 0
                                        end
                                        B_lvl_q_3 = B_lvl_q
                                        if B_lvl_q < B_lvl_q_step
                                            B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                        else
                                            B_lvl_i_stop_3 = 0
                                        end
                                        phase_stop_9 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                        if phase_stop_9 >= 1
                                            k = 1
                                            if A_lvl_tbl2[A_lvl_q] < 1
                                                A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            if B_lvl_tbl1[B_lvl_q] < 1
                                                B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                            end
                                            while k <= phase_stop_9
                                                A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                A_lvl_q_step = A_lvl_q
                                                if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                    A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                phase_stop_10 = min(B_lvl_i_3, phase_stop_9, A_lvl_i)
                                                if A_lvl_i == phase_stop_10 && B_lvl_i_3 == phase_stop_10
                                                    B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                                    A_lvl_q_2 = A_lvl_q
                                                    if A_lvl_q < A_lvl_q_step
                                                        A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                    else
                                                        A_lvl_i_stop_2 = 0
                                                    end
                                                    phase_stop_11 = min(i_13, A_lvl_i_stop_2)
                                                    if phase_stop_11 >= i_13
                                                        if A_lvl_tbl1[A_lvl_q] < i_13
                                                            A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_13, A_lvl_q, A_lvl_q_step - 1)
                                                        end
                                                        while true
                                                            A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                            if A_lvl_i_2 < phase_stop_11
                                                                A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                A_lvl_q_2 += 1
                                                            else
                                                                phase_stop_13 = min(A_lvl_i_2, phase_stop_11)
                                                                if A_lvl_i_2 == phase_stop_13
                                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                    A_lvl_q_2 += 1
                                                                end
                                                                break
                                                            end
                                                        end
                                                    end
                                                    A_lvl_q = A_lvl_q_step
                                                    B_lvl_q_3 += 1
                                                elseif B_lvl_i_3 == phase_stop_10
                                                    B_lvl_q_3 += 1
                                                elseif A_lvl_i == phase_stop_10
                                                    A_lvl_q = A_lvl_q_step
                                                end
                                                k = phase_stop_10 + 1
                                            end
                                        end
                                    end
                                end
                            end
                        Ct_lvl_2_val = val_4
                        A_lvl_ptr = A_lvl_ptr_3
                        A_lvl_tbl1 = A_lvl_tbl1_3
                        A_lvl_tbl2 = A_lvl_tbl2_3
                        A_lvl_val = val_5
                        B_lvl_ptr = B_lvl_ptr_3
                        B_lvl_tbl1 = B_lvl_tbl1_3
                        B_lvl_tbl2 = B_lvl_tbl2_3
                        B_lvl_val = val_6
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_19 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_19
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_19
                            val_7 = Ct_lvl_2_val
                            Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                            A_lvl_ptr_4 = A_lvl_ptr
                            A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                            A_lvl_tbl1_4 = A_lvl_tbl1
                            A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                            A_lvl_tbl2_4 = A_lvl_tbl2
                            A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                            val_8 = A_lvl_val
                            A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                            B_lvl_ptr_4 = B_lvl_ptr
                            B_lvl_tbl1_4 = B_lvl_tbl1
                            B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                            B_lvl_tbl2_4 = B_lvl_tbl2
                            val_9 = B_lvl_val
                            B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                            Threads.@threads for i_20 = 1:Threads.nthreads()
                                    phase_start_22 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_20), Threads.nthreads()))
                                    phase_stop_24 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_20, Threads.nthreads()))
                                    if phase_stop_24 >= phase_start_22
                                        for i_23 = phase_start_22:phase_stop_24
                                            Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_23
                                            A_lvl_q = A_lvl_ptr[1]
                                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                            if A_lvl_q < A_lvl_q_stop
                                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                            else
                                                A_lvl_i_stop = 0
                                            end
                                            B_lvl_q_3 = B_lvl_q
                                            if B_lvl_q < B_lvl_q_step
                                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                            else
                                                B_lvl_i_stop_3 = 0
                                            end
                                            phase_stop_25 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                            if phase_stop_25 >= 1
                                                k = 1
                                                if A_lvl_tbl2[A_lvl_q] < 1
                                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                if B_lvl_tbl1[B_lvl_q] < 1
                                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                                end
                                                while k <= phase_stop_25
                                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                    A_lvl_q_step = A_lvl_q
                                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                    end
                                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                    phase_stop_26 = min(B_lvl_i_3, A_lvl_i, phase_stop_25)
                                                    if A_lvl_i == phase_stop_26 && B_lvl_i_3 == phase_stop_26
                                                        B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                                        A_lvl_q_4 = A_lvl_q
                                                        if A_lvl_q < A_lvl_q_step
                                                            A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                        else
                                                            A_lvl_i_stop_4 = 0
                                                        end
                                                        phase_stop_27 = min(i_23, A_lvl_i_stop_4)
                                                        if phase_stop_27 >= i_23
                                                            if A_lvl_tbl1[A_lvl_q] < i_23
                                                                A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_23, A_lvl_q, A_lvl_q_step - 1)
                                                            end
                                                            while true
                                                                A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                                if A_lvl_i_4 < phase_stop_27
                                                                    A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                    A_lvl_q_4 += 1
                                                                else
                                                                    phase_stop_29 = min(A_lvl_i_4, phase_stop_27)
                                                                    if A_lvl_i_4 == phase_stop_29
                                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                        A_lvl_q_4 += 1
                                                                    end
                                                                    break
                                                                end
                                                            end
                                                        end
                                                        A_lvl_q = A_lvl_q_step
                                                        B_lvl_q_3 += 1
                                                    elseif B_lvl_i_3 == phase_stop_26
                                                        B_lvl_q_3 += 1
                                                    elseif A_lvl_i == phase_stop_26
                                                        A_lvl_q = A_lvl_q_step
                                                    end
                                                    k = phase_stop_26 + 1
                                                end
                                            end
                                        end
                                    end
                                end
                            Ct_lvl_2_val = val_7
                            A_lvl_ptr = A_lvl_ptr_4
                            A_lvl_tbl1 = A_lvl_tbl1_4
                            A_lvl_tbl2 = A_lvl_tbl2_4
                            A_lvl_val = val_8
                            B_lvl_ptr = B_lvl_ptr_4
                            B_lvl_tbl1 = B_lvl_tbl1_4
                            B_lvl_tbl2 = B_lvl_tbl2_4
                            B_lvl_val = val_9
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.08838669783079417, 0.24540062578718655, 0.0, 0.0, 0.0, 0.0, 0.2598139726110033, 0.0, 0.0, 0.008999058499533074, 0.10561231293601407, 0.018993358540021866, 0.3713088213439608, 0.1272213104915037, 0.0, 0.04569648380052932, 0.0, 0.6778277114032399, 0.0, 1.0116444857173326, 0.1419594034849179, 0.849786220982489, 0.1853715018708835, 0.0, 0.41575027296468353, 0.027919812909200686, 0.38129764067914484, 0.0, 0.010472223603003109, 0.32765224234190193, 0.0, 0.0, 0.0, 0.27657062580546904, 0.018635375946533275, 0.0, 0.6553105493426397, 0.1806768240966126, 0.0, 0.0, 0.13022235819683495, 0.0, 0.0, 0.0096207645890863, 0.0, 0.0, 0.0, 0.0, 0.0027620603050478813, 0.0, 0.0, 0.0, 0.0, 0.06777735948867263, 0.16424694314849322, 0.05466156243395641, 0.0, 0.3550122664783007, 0.0, 0.16598631348758813, 0.0, 0.09916577661749644, 0.0, 0.0, 0.017171766504479664, 0.14883499722913907, 0.14454297081157494, 0.0, 0.0, 0.0, 0.08135785354072747, 0.18934501987281463, 0.0, 0.0, 0.0, 0.043171173549343585, 0.04442771737900286, 0.0, 0.0, 0.16847976307679274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4519419326045341, 0.0022494085401006682, 0.0, 0.09264806290445121, 0.0, 0.0, 0.5779259042074504, 0.0, 0.0, 0.0, 0.01319039039025495, 0.0, 0.0, 0.05821123759190987, 0.008570313787111606, 0.12498925860233108, 0.3161944438230963, 0.0, 0.0, 0.0, 0.0, 0.03428001709676162, 0.0, 0.0, 0.0, 0.4239046512601812, 0.0, 0.0, 0.0, 0.0, 0.006439869364205756, 0.0, 0.19268641103781292, 0.0, 0.0, 0.0, 0.13842608775449636, 0.7754112567712441, 0.5650474898241402, 0.16678352690096504, 0.0, 0.0, 0.26721012017234747, 0.0, 0.0, 0.40379612390902914, 0.0, 0.5616249905190419, 0.0, 0.0, 0.0, 0.05914491909738165, 0.0, 0.0, 0.5796881176474965, 0.0, 0.0, 0.0, 0.0, 0.19259492607938428, 0.5396680351153355, 0.1002017616669876, 0.0, 0.0, 0.07018769309449151, 0.0, 0.0, 0.0, 0.8890997886610695, 0.01580855669802033, 0.07592126473643429, 0.0, 0.0, 0.5327597008182733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650628783183555, 0.0, 0.0, 0.4177758368274485, 0.01847646120309497, 0.2474671864399932, 0.030137257707486417, 0.0, 0.0, 0.0, 0.0, 0.4333965515966774, 0.0, 0.025363517487659904, 0.0, 0.0, 0.28727696476738296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48463873218296616, 0.3619901497543638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3095355097692787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08881016246594031, 0.0864536634210502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13334438240099766, 0.0, 0.2743296378950603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21573236386631758, 0.138874394226427, 0.21526827303910834, 0.0, 0.8276738568887637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13803323038392623, 0.0, 0.0, 0.18937725647626488, 0.0, 0.09756025088965181, 0.10247093349242449, 0.14247269057616566, 0.0, 0.4644170645216008, 0.0, 0.0, 0.0, 0.6396576582705668, 0.0, 0.14648223852485512, 0.0, 0.3845502326592231, 0.0, 0.0, 0.0, 0.0, 0.01873756402105984, 0.01865952833886222, 0.015020499411212522, 0.0, 0.11259829701043601, 0.13537240455394534, 0.18963280616455852, 0.0, 0.1732077631723114, 0.0, 0.009279305276553587, 0.0, 0.09430577452314615, 0.07566718263303025, 0.06172210939249301, 0.0, 0.0, 0.0017837976727260341, 0.0, 0.0, 0.06543462567823881, 0.0621898641418941, 0.0, 0.0, 0.0, 0.41468742426256355, 0.21475258071539002, 0.0, 0.0, 0.08728790458911416, 0.0, 0.0, 0.4956863169283368, 0.0, 0.0, 0.3312300382813116, 0.0, 0.6814401538748236, 0.017040189816468283, 0.0, 0.0, 0.0, 0.0, 0.1702496303089558, 0.04558027585085677, 0.0, 0.0, 0.05652088848846798, 0.0, 0.0, 0.039516412285590885, 0.04836078861030929, 0.0, 0.0, 0.0, 0.0066658135086557066, 0.28756231542228783, 0.0, 0.0, 0.005213055047386901, 0.0, 0.03077146873270733, 0.0, 0.18174661292486113, 0.011855817392138795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2550943184597343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19130663987033655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795782309469964, 0.4949588224757624, 0.10547057221471998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428147611319233, 0.0, 0.4336529209634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981699391447328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14060207841669792, 0.19125923680987167, 0.17120811796462362, 0.0, 0.0, 0.29682703146376954, 0.2309028098716656, 0.0, 0.3415808438027304, 0.5413871431291847, 0.19010077735847383, 0.0, 0.0, 0.0, 0.037176095928915485, 0.0, 0.0, 0.19621484736356867, 0.46400800412758475, 0.6251709107930822, 0.11840971377140953, 0.5297289566486542, 0.0, 0.0, 0.0629827610017505, 0.0, 0.30811879649367063, 0.0, 0.43390554368076734, 0.0, 0.3078202365484454, 0.0, 0.0, 0.06464271443386868, 0.0, 0.0, 0.7925386152607364, 0.0, 0.0, 0.0, 0.0, 0.4871987999416911, 0.0, 0.0, 0.0, 0.026241068751647587, 0.4048536827096608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667237073016084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008398941803472277, 0.0, 0.3462604046867109, 0.0, 0.41520221547875746, 0.0, 0.0, 0.0, 0.49209502240450126, 0.6693906625198521, 0.19758221668125867, 0.008160985490142467, 0.2605302099636665, 0.0, 0.0, 0.0, 0.9022483783960523, 1.0694729952381887, 0.6653361553880242, 0.881281776229774, 0.001915716390555032, 0.022482711824403312, 0.0040432994483474245, 0.0, 0.3214035783779074, 0.6867348676262818, 0.0, 0.6858420722534031, 0.0, 0.5811377322397425, 0.04246482918579259, 0.11467932906673921, 0.09709202075873843, 0.0, 0.0, 0.0, 0.2200140216993193, 0.0, 0.7507517442378999, 0.0, 0.0, 0.7372603142185328, 0.0, 0.006741369353138395, 0.8069776586909365, 0.00396709224045839, 0.0, 0.0, 0.0, 0.6101879525945185, 0.0, 0.0, 0.026258353794755256, 0.4016774417320984, 0.014813931005383318, 0.6190727226045784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11309418362565873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036526440507301174, 0.022956711251180283, 0.40907708831845013, 0.0012453094708774737, 0.0, 0.0, 0.0, 0.0, 0.014062827632021033, 0.0, 0.0, 0.0, 0.006394809610240893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21784527989974428, 0.0, 0.0, 0.0, 0.3180108962002836, 0.2508741672819204, 0.17523704698611114, 0.13837147224686994, 0.27935616728122964, 0.1859955338163167, 0.0, 0.06462126637992056, 1.0008493550472979, 0.6004231261661688, 0.0, 0.3940831570768702, 0.0, 0.0, 0.1305734964236071, 0.0, 0.09786792103897592, 0.0, 0.11654231814191775, 0.46697515894469777, 0.5700094853415558, 0.1107417067979406, 0.346111937724667, 0.0, 0.1225882117910605, 0.0, 0.28673152989464684, 0.0, 0.12654022793408917, 0.0, 0.0, 0.45809293367016757, 0.3647743355850667, 0.817304098176075, 0.0036334642288677415, 0.0, 0.2669922423479005, 0.0, 0.0, 0.0, 0.32457729111200295, 0.5543705739187803, 0.8812247175026642, 0.16912005088903598, 0.5020073987686707, 0.0, 0.09252856828989332, 0.0, 0.0, 0.0, 0.06948083164247039, 0.2588335470174883, 0.23431107957691064, 0.0, 0.0, 0.4609326565956409, 0.0981996119487529, 0.0, 0.0, 0.0, 0.0, 0.41461953421729686, 0.2880401034246727, 0.0, 0.12878680297473977, 0.5528442548314576, 0.8638211211778427, 0.0, 0.19329232440572794, 0.07190135483727589, 0.0, 0.37985878824980135, 0.0, 0.0, 0.47943873587199365, 0.0, 0.1632157826430328, 0.028602417984395823, 0.12587604601890898, 0.20239239184313712, 0.0, 0.9957002205667365, 0.5403020941861382, 0.1731723605204449, 0.5984215188307392, 0.5906299727726914, 0.15421128542459664, 0.22417177182593684, 0.14760215442934868, 0.0, 0.0, 0.10452572448334531, 0.0, 0.0, 0.5192893646261969, 0.0, 0.0, 0.0, 0.03548389098440683, 0.0, 0.0, 0.5359908824860568, 0.0, 0.0, 0.4508397689271815, 0.17912612646003018, 0.05191685886593687, 0.015041105758856862, 0.0, 0.0, 0.07792048637164595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16284516279577882, 0.07019827463547235, 0.0, 0.0017166852898648512, 0.022601665621833984, 0.0, 0.0, 0.0, 0.08820522946301469, 0.0, 0.0, 0.4597721334804677, 0.0, 0.01968862180697655, 0.1496625833744818, 0.0, 0.0, 0.0, 0.0, 0.042967175515187854, 0.0, 0.5925889649898668, 0.03501818713399176, 0.0, 0.23929946904107768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.586042846539397, 0.0, 0.35012160211964255, 0.0, 0.0, 0.2671275149044985, 0.5254872140248491, 0.0, 0.0, 0.0, 0.4346599048698998, 0.0, 0.6685147232492785, 0.0, 0.0, 0.006603260891096502, 0.41222164853295895, 0.691126666160783, 0.3115253982735278, 0.0, 0.5948463934358659, 0.0, 0.6104915934501508, 0.0, 0.10122959156761935, 0.0, 0.0, 0.4361142638019697, 0.0, 0.0, 0.022953207777356696, 0.01768983406390727, 0.0, 0.49300859199961644, 0.0, 0.45242065570193146, 0.0, 0.25296290668039206, 0.24913417193879323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036117281801281323, 0.37981219294125684, 0.0, 0.7813883080906168, 0.37787984308171674, 0.0, 0.3540795182413977, 0.0, 0.0, 0.024079641916532137, 0.0, 0.3372996465844834, 0.4587109366214878, 0.0, 0.0, 0.0, 0.0, 0.008167928328435794, 0.30985126085873477, 0.0, 0.1769552845849796, 0.01014740975340464, 0.3239445526321744, 0.2589119416659987, 0.30500724408067964, 0.0, 0.8521343659652334, 0.0, 0.12278148254603906, 0.0, 0.0, 0.7559317032710442, 0.0, 0.4639073457870384, 0.3375990135598286, 0.0, 0.09771802789528808, 0.0, 0.0, 0.0, 0.0, 0.14259284539732897, 0.0, 0.0, 0.0, 0.03978581978010784, 0.4979059043742451, 0.0, 0.0, 0.02239395579386129, 0.0, 0.0, 0.08552679542089565, 0.0, 0.28975782063069117, 0.4544199284136855, 0.4879966224465369, 0.0, 0.5198773678370044, 0.09074414747732065, 0.0, 0.0, 0.0, 0.08751115961530397, 0.0, 0.0, 0.0, 0.0, 0.01723069885490719, 0.005476104703094391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018363845689630152, 0.0, 0.0, 0.0, 0.03456818780211805, 0.16076784648973388, 0.1339929852951158, 0.12939203287442297, 0.6506668934574178, 0.07556479761019191, 0.0, 0.0, 0.1120835499344092, 0.004448105032597938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424200452243984, 0.21870476868551994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04400733534916703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5084860468121182, 0.0, 0.0, 0.0, 0.06613225218879751, 0.0, 0.0, 0.03227907593043655, 0.0, 0.01489513919323321, 0.0, 0.0, 0.0004903768608608706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709186680024144, 0.0057636955333438475, 0.0, 0.0, 0.0, 0.0, 0.05167292145382253, 0.03114794005970685, 0.0, 0.0, 0.0, 0.04406332427000894, 0.0, 0.28333618254852055, 0.0, 0.0, 0.08754290037370453, 0.0, 0.030717709851121017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15375069919642081, 0.17266284464812964, 0.0, 0.0, 0.0, 0.0, 0.4591427931520538, 0.0, 0.0, 0.4080740928256236, 0.04867028613084824, 0.0, 0.0, 0.19198247076461217, 0.0, 0.0, 0.0, 0.04903912896069461, 0.0, 0.0, 0.0, 0.03565133307467186, 0.011864802664565318, 0.0, 0.0770587282490205, 0.06882991093352155, 0.0, 0.32659059563162995, 0.036557980918752765, 0.0, 0.0, 0.0, 0.0, 0.03137440184410096, 0.0, 0.0, 0.0, 0.18642661293603366, 0.0, 0.0, 0.0, 0.0, 0.06772257249589227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21100355273002191, 0.0, 1.3416336420880526, 0.0, 0.0, 0.46161810723264507, 0.0, 0.4582995461192519, 0.05104879083246295, 0.5773364122618407, 0.57352236887648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640999064171196, 0.6666836020552119, 0.06886868779194379, 0.564904097158741, 0.0, 0.3210670084651615, 0.0, 0.0, 0.0, 0.9392890324745945, 0.0, 0.0, 0.2984250122811811, 0.0, 0.009405052137469182, 0.0, 0.39950267169818077, 0.07050196115427894, 0.824636783426293, 0.4953951141450468, 0.0, 0.0, 0.34635403119710667, 0.8798483938054087, 0.39347138128916365, 0.0, 0.0, 0.41085938784277987, 0.0, 0.7572672907360996, 0.0, 0.1918766456362537, 0.14775814623354722, 0.0, 0.0, 0.18414622884752666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32881972797464193, 0.22733765531865868, 0.29775899283396906, 0.0, 0.0, 0.0, 0.0387256895819095, 0.5151993362991701, 0.0, 0.0, 0.0, 0.008722287803381279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780184121162673, 0.0, 0.0, 0.0, 0.0, 0.0511079535437104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05738054033260683, 0.0, 0.0, 0.3177388426930726, 0.0, 0.0, 0.0019725686702392773, 0.0, 0.0, 0.0, 0.0, 0.20770780211002965, 0.0, 0.0, 0.0, 0.8220710140576788, 0.0, 0.0, 0.0, 0.0, 0.9922981121231631, 0.19272059014741777, 0.18871634512759347, 0.009978475777936804, 0.5372065554785002, 0.0, 0.0, 0.17523452577386275, 1.0717089910255204, 0.5571949298413089, 0.0, 0.3237380570219946, 0.0, 1.1122472434174695, 0.10030606802210519, 0.0, 0.42164300445661296, 0.0, 0.2034243141927581, 0.0, 1.0210169552267845, 0.19689099390765805, 0.14675887656145528, 0.15859984719751974, 0.2247981968120587, 0.0, 0.22026608101531156, 0.5078755745015515, 0.2690121908665218, 0.0, 0.0, 0.0, 0.3746062674772627, 0.7584612913730437, 0.0, 0.0, 0.8749551201631387, 0.5887430555293698, 0.8247249363546676, 0.21469878981542115, 1.002630449124598, 0.2572736542055717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005299432156408299, 0.06219376030445952, 0.011184949515597283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11747014454387752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1628689565677918, 0.010974138077104432, 0.0, 0.0, 0.0, 0.0, 1.0297896192318396, 0.0, 0.662355409415741, 0.5720482757502646, 0.3113118281374319, 0.0, 0.0, 0.25393001900118484, 0.02276308091998572, 0.03508485404358758, 0.45957926224802004, 0.0, 0.05036277933399867, 0.1447652248957086, 0.0, 0.0242600552046752, 0.005732716773973234, 0.0, 0.0, 0.04566723978074626, 0.007798132412071851, 0.435160826872351, 0.19099152935556227, 0.0, 0.09109198019072849, 0.0, 0.0, 0.0, 0.0, 0.040872817508571836, 0.0, 0.8816978299630381, 0.023385944730671186, 0.20852512378086208, 0.3265908462108258, 0.0, 0.8135187830099228, 0.5004561612521131, 0.5929930445509373, 0.07024535595608956, 0.4293153063068892, 0.33966138448698774, 0.0, 0.0, 0.219723330992236, 0.0, 0.0, 0.32087091161635517, 0.10046935863374477, 0.0, 0.21249664109114016, 0.0, 0.0, 0.5675920409330384, 0.0, 0.0, 0.02195446551553763, 0.0, 0.0, 0.0, 0.7828555360473642, 0.0, 0.0, 0.0, 0.539158201637973, 0.0, 0.037194676308406484, 0.0, 0.5899620450765102, 0.0, 1.064333300573155, 0.0, 0.4126616356723095, 0.0, 0.0, 0.0, 0.0, 0.005455259856546277, 0.06532462900349355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6382915607944724, 0.0, 0.1058392854111573, 0.06419509685388734, 0.0, 0.0, 0.42600921169580896, 0.0, 0.6948705846598551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7494592390120385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34703521803027376, 0.47959926529853425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954560408868362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04058791510732469, 0.0, 0.0, 0.0, 0.026371559760006224, 0.46735915191246824, 0.9729562858716514, 0.0, 0.01593384874339247, 0.0, 0.0, 0.10548242945325798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182217469250767, 0.0, 0.0, 0.0, 0.0, 0.5929119201290493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0028851424117770368, 0.14902256810885017, 0.0, 0.19393473922191487, 0.0010822975481770052, 0.10083006827906865, 0.005589290532560041, 0.0, 0.0377329438822351, 0.0, 0.0, 0.0, 0.0, 0.08622227292139113, 0.0, 0.0, 0.052960874748722735, 0.0, 0.0, 0.0, 0.040542431602682394, 0.0, 0.034748695303796415, 0.0, 0.0, 0.07778126624009696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08990369242695052, 0.0, 0.0, 0.0, 0.0, 0.1714300400506459, 0.23319412483505944, 0.06883127399553583, 0.0, 0.0, 0.4520065142603474, 0.7559043080573538, 0.0, 0.9918256875421747, 0.34148047573693957, 0.23178166527267935, 0.1984049383893502, 0.0, 0.0, 0.0, 0.4618215114400494, 0.055660721213669, 0.23923628669541208, 0.0, 0.0, 0.39945045771087084, 0.3329245273531598, 0.25602890393383043, 0.0, 0.2574713970419185, 0.0, 0.0, 0.27848743576980106, 0.008801495971424074, 0.0, 0.0, 0.0, 0.0, 0.4961604274582618, 0.0, 0.0, 0.5434029369831717, 0.0, 0.0, 0.0, 0.0, 0.15767180411659634, 0.03460197933312267, 0.0, 0.0, 0.036131085316488384, 0.0, 0.0, 0.0, 0.016873683938744447, 0.019906225883667222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012507180486519448, 0.0, 0.02685500739865508, 0.028916495513405534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029742024653825302, 1.0585077478673894, 0.0, 0.0, 0.10450313655197234, 0.0, 0.27087506529662764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7518068036153462, 0.0, 0.2680435440340337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1316435251098364, 0.8078731280911045, 0.0, 0.0, 0.0, 0.10506968633342718, 0.23470506622896917, 0.0, 0.0, 0.607722294332459, 0.023665118775296444, 0.014839085130224942, 0.0, 0.0, 0.24386571546932873, 0.0, 0.0, 0.3502050356771847, 0.0, 0.0, 0.46379933676520235, 0.0, 0.08440789641107996, 0.04593440835303492, 0.021386035200774683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7729032574550468, 0.0, 0.11781868003483978, 0.030607043037187642, 0.0, 0.1726108187023696, 0.09583059716129254, 0.5239548125179947, 0.4366934746091282, 0.0, 0.0, 0.24627150409293175, 0.0, 0.13007997889130285, 0.36528893478699903, 0.18318396866765946, 0.0, 0.011811348038501769, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1723218684731558, 0.5524938653991974, 0.7739462295109258, 0.0, 0.7069108871009565, 0.0, 1.1639912229987677, 0.0, 0.0737216927746314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41689243790078717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7826638975615551, 0.0, 0.0, 0.0, 0.1017910453533696, 0.0, 0.0, 0.0, 0.0, 0.022926661938484392, 0.0, 0.0, 0.24172521220469304, 0.33406187082542654, 0.0, 0.0, 0.31010342596966556, 0.0, 0.0, 1.1081747068991343, 0.7344335908166203, 0.16327913698089802, 0.7325151937485493, 0.17384385605370836, 0.08371482373128411, 0.0, 0.3420940653006234, 0.0, 0.04990946505718503, 0.5498243469410863, 0.0, 0.007722420577405236, 0.0906297807361463, 0.016298894248894004, 0.0, 0.17760842474448457, 0.7445477489471244, 0.0, 0.0, 0.23271741543898974, 0.5862478840032251, 0.38013450552556605, 0.0, 0.13625107884748244, 0.3102878234624971, 0.0, 0.0, 0.0613418632643825, 0.1222024301534575, 0.0, 0.0, 0.09768999149541487, 0.07432603695941839, 0.0, 0.0, 0.2373353492409029, 0.8187850328888507, 0.0, 0.1472545596990393, 0.08055057930039017, 0.0, 0.0, 0.0, 0.0, 0.022056121851574153, 0.7041166858972707, 0.0, 0.0, 0.0, 0.7708181971148897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6591456110142444, 0.0, 0.0, 0.0, 0.5151326583061712, 0.4293405940090164, 0.0, 0.30993576190130123, 0.24212487706484054, 0.0, 0.0, 0.35913833699197834, 0.594616431743019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7007742613782065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07822848175716028, 0.0, 0.795037704009975, 0.0, 0.18176747614492506, 0.0, 0.0, 0.0, 0.0, 0.05218428597433502, 0.551641665900435, 0.0, 0.0, 0.0, 0.0, 0.4173251650328503, 0.13888627164939463, 0.0, 0.9020292850308806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32443041606173034, 0.0, 0.3672605285185933, 0.0, 0.0, 0.0, 0.20671726976925492, 0.0, 0.0, 0.38426107037286794, 0.0, 0.0, 1.3158788906540237, 0.0, 0.0, 0.33314012692337136, 0.4077019730262151]), 42), 42)),)

