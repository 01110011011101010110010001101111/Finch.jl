julia> @finch begin
        CR .= 0
        for i = _
            for j = _
                for k = _
                    CR[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(CR = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            phase_start_2 = max(1, 1 + fld(A_lvl.shape[1] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                for i_7 = phase_start_2:phase_stop_2
                    B_lvl_q = B_lvl_ptr[1]
                    B_lvl_q_stop = B_lvl_ptr[1 + 1]
                    if B_lvl_q < B_lvl_q_stop
                        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                    else
                        B_lvl_i_stop = 0
                    end
                    phase_stop_3 = min(B_lvl.shape[2], B_lvl_i_stop)
                    if phase_stop_3 >= 1
                        if B_lvl_tbl2[B_lvl_q] < 1
                            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        while true
                            B_lvl_i = B_lvl_tbl2[B_lvl_q]
                            B_lvl_q_step = B_lvl_q
                            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                            end
                            if B_lvl_i < phase_stop_3
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_5 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_5 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_5
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_6 = min(B_lvl_i_2, phase_stop_5, A_lvl_i)
                                        if A_lvl_i == phase_stop_6 && B_lvl_i_2 == phase_stop_6
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_7 = min(i_7, A_lvl_i_stop_2)
                                            if phase_stop_7 >= i_7
                                                if A_lvl_tbl1[A_lvl_q] < i_7
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_7
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_9 = min(A_lvl_i_2, phase_stop_7)
                                                        if A_lvl_i_2 == phase_stop_9
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_6
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_6
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_6 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            else
                                phase_stop_14 = min(B_lvl_i, phase_stop_3)
                                if B_lvl_i == phase_stop_14
                                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_14
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_15 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_15 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_15
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_16 = min(B_lvl_i_2, A_lvl_i, phase_stop_15)
                                            if A_lvl_i == phase_stop_16 && B_lvl_i_2 == phase_stop_16
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_17 = min(i_7, A_lvl_i_stop_4)
                                                if phase_stop_17 >= i_7
                                                    if A_lvl_tbl1[A_lvl_q] < i_7
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_17
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_19 = min(A_lvl_i_4, phase_stop_17)
                                                            if A_lvl_i_4 == phase_stop_19
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_16
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_16
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_16 + 1
                                        end
                                    end
                                    B_lvl_q = B_lvl_q_step
                                end
                                break
                            end
                        end
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    for i_4 = 1:A_lvl.shape[1]
        val = Ct_lvl_2_val
        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
        B_lvl_ptr_2 = B_lvl_ptr
        B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
        B_lvl_tbl1_2 = B_lvl_tbl1
        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
        B_lvl_tbl2_2 = B_lvl_tbl2
        B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
        val_2 = B_lvl_val
        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
        A_lvl_ptr_2 = A_lvl_ptr
        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
        A_lvl_tbl1_2 = A_lvl_tbl1
        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
        A_lvl_tbl2_2 = A_lvl_tbl2
        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
        val_3 = A_lvl_val
        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
        Threads.@threads for i_5 = 1:Threads.nthreads()
                B_lvl_q = B_lvl_ptr[1]
                B_lvl_q_stop = B_lvl_ptr[1 + 1]
                if B_lvl_q < B_lvl_q_stop
                    B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                else
                    B_lvl_i_stop = 0
                end
                phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_5 + -1), Threads.nthreads()))
                phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_5, Threads.nthreads()))
                if phase_stop_2 >= phase_start_2
                    if B_lvl_tbl2[B_lvl_q] < phase_start_2
                        B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    while true
                        B_lvl_i = B_lvl_tbl2[B_lvl_q]
                        B_lvl_q_step = B_lvl_q
                        if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                            B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        if B_lvl_i < phase_stop_2
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_4, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_4
                                            if A_lvl_tbl1[A_lvl_q] < i_4
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        else
                            phase_stop_13 = min(B_lvl_i, phase_stop_2)
                            if B_lvl_i == phase_stop_13
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_4, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_4
                                                if A_lvl_tbl1[A_lvl_q] < i_4
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            end
                            break
                        end
                    end
                end
            end
        Ct_lvl_2_val = val
        B_lvl_ptr = B_lvl_ptr_2
        B_lvl_tbl1 = B_lvl_tbl1_2
        B_lvl_tbl2 = B_lvl_tbl2_2
        B_lvl_val = val_2
        A_lvl_ptr = A_lvl_ptr_2
        A_lvl_tbl1 = A_lvl_tbl1_2
        A_lvl_tbl2 = A_lvl_tbl2_2
        A_lvl_val = val_3
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        for i_6 = 1:A_lvl.shape[1]
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_6
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_6, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_6
                                            if A_lvl_tbl1[A_lvl_q] < i_6
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_6, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                        end
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_13 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_13
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                            for i_8 = 1:A_lvl.shape[1]
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_8
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_8, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_8
                                                if A_lvl_tbl1[A_lvl_q] < i_8
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_8, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    B_lvl_q = B_lvl_ptr[1]
    B_lvl_q_stop = B_lvl_ptr[1 + 1]
    if B_lvl_q < B_lvl_q_stop
        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
    else
        B_lvl_i_stop = 0
    end
    phase_stop = min(B_lvl.shape[2], B_lvl_i_stop)
    if phase_stop >= 1
        if B_lvl_tbl2[B_lvl_q] < 1
            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
        end
        while true
            B_lvl_i = B_lvl_tbl2[B_lvl_q]
            B_lvl_q_step = B_lvl_q
            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
            end
            if B_lvl_i < phase_stop
                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                val = Ct_lvl_2_val
                Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                B_lvl_tbl1_2 = B_lvl_tbl1
                B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                B_lvl_tbl2_2 = B_lvl_tbl2
                val_2 = B_lvl_val
                B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                A_lvl_ptr_2 = A_lvl_ptr
                A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                A_lvl_tbl1_2 = A_lvl_tbl1
                A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                A_lvl_tbl2_2 = A_lvl_tbl2
                A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                val_3 = A_lvl_val
                A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                Threads.@threads for i_9 = 1:Threads.nthreads()
                        phase_start_6 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_9), Threads.nthreads()))
                        phase_stop_7 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_9, Threads.nthreads()))
                        if phase_stop_7 >= phase_start_6
                            for i_12 = phase_start_6:phase_stop_7
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_12
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_8 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_8 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_8
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_9 = min(B_lvl_i_2, phase_stop_8, A_lvl_i)
                                        if A_lvl_i == phase_stop_9 && B_lvl_i_2 == phase_stop_9
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_10 = min(i_12, A_lvl_i_stop_2)
                                            if phase_stop_10 >= i_12
                                                if A_lvl_tbl1[A_lvl_q] < i_12
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_12, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_10
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_12 = min(A_lvl_i_2, phase_stop_10)
                                                        if A_lvl_i_2 == phase_stop_12
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_9
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_9
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_9 + 1
                                    end
                                end
                            end
                        end
                    end
                Ct_lvl_2_val = val
                B_lvl_tbl1 = B_lvl_tbl1_2
                B_lvl_tbl2 = B_lvl_tbl2_2
                B_lvl_val = val_2
                A_lvl_ptr = A_lvl_ptr_2
                A_lvl_tbl1 = A_lvl_tbl1_2
                A_lvl_tbl2 = A_lvl_tbl2_2
                A_lvl_val = val_3
                B_lvl_q = B_lvl_q_step
            else
                phase_stop_18 = min(B_lvl_i, phase_stop)
                if B_lvl_i == phase_stop_18
                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_18
                    val_4 = Ct_lvl_2_val
                    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                    B_lvl_tbl1_3 = B_lvl_tbl1
                    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                    B_lvl_tbl2_3 = B_lvl_tbl2
                    val_5 = B_lvl_val
                    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                    A_lvl_ptr_3 = A_lvl_ptr
                    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                    A_lvl_tbl1_3 = A_lvl_tbl1
                    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                    A_lvl_tbl2_3 = A_lvl_tbl2
                    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                    val_6 = A_lvl_val
                    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                    Threads.@threads for i_19 = 1:Threads.nthreads()
                            phase_start_21 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_19), Threads.nthreads()))
                            phase_stop_23 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_19, Threads.nthreads()))
                            if phase_stop_23 >= phase_start_21
                                for i_22 = phase_start_21:phase_stop_23
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_22
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_24 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_24 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_24
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_25 = min(B_lvl_i_2, A_lvl_i, phase_stop_24)
                                            if A_lvl_i == phase_stop_25 && B_lvl_i_2 == phase_stop_25
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_26 = min(i_22, A_lvl_i_stop_4)
                                                if phase_stop_26 >= i_22
                                                    if A_lvl_tbl1[A_lvl_q] < i_22
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_22, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_26
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_28 = min(A_lvl_i_4, phase_stop_26)
                                                            if A_lvl_i_4 == phase_stop_28
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_25
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_25
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_25 + 1
                                        end
                                    end
                                end
                            end
                        end
                    Ct_lvl_2_val = val_4
                    B_lvl_tbl1 = B_lvl_tbl1_3
                    B_lvl_tbl2 = B_lvl_tbl2_3
                    B_lvl_val = val_5
                    A_lvl_ptr = A_lvl_ptr_3
                    A_lvl_tbl1 = A_lvl_tbl1_3
                    A_lvl_tbl2 = A_lvl_tbl2_3
                    A_lvl_val = val_6
                    B_lvl_q = B_lvl_q_step
                end
                break
            end
        end
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        val_4 = Ct_lvl_2_val
                        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                        A_lvl_ptr_3 = A_lvl_ptr
                        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                        A_lvl_tbl1_3 = A_lvl_tbl1
                        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                        A_lvl_tbl2_3 = A_lvl_tbl2
                        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                        val_5 = A_lvl_val
                        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                        B_lvl_ptr_3 = B_lvl_ptr
                        B_lvl_tbl1_3 = B_lvl_tbl1
                        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                        B_lvl_tbl2_3 = B_lvl_tbl2
                        val_6 = B_lvl_val
                        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                        Threads.@threads for i_10 = 1:Threads.nthreads()
                                phase_start_7 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_10), Threads.nthreads()))
                                phase_stop_8 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_10, Threads.nthreads()))
                                if phase_stop_8 >= phase_start_7
                                    for i_13 = phase_start_7:phase_stop_8
                                        Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_13
                                        A_lvl_q = A_lvl_ptr[1]
                                        A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                        if A_lvl_q < A_lvl_q_stop
                                            A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                        else
                                            A_lvl_i_stop = 0
                                        end
                                        B_lvl_q_3 = B_lvl_q
                                        if B_lvl_q < B_lvl_q_step
                                            B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                        else
                                            B_lvl_i_stop_3 = 0
                                        end
                                        phase_stop_9 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                        if phase_stop_9 >= 1
                                            k = 1
                                            if A_lvl_tbl2[A_lvl_q] < 1
                                                A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            if B_lvl_tbl1[B_lvl_q] < 1
                                                B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                            end
                                            while k <= phase_stop_9
                                                A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                A_lvl_q_step = A_lvl_q
                                                if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                    A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                phase_stop_10 = min(B_lvl_i_3, phase_stop_9, A_lvl_i)
                                                if A_lvl_i == phase_stop_10 && B_lvl_i_3 == phase_stop_10
                                                    B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                                    A_lvl_q_2 = A_lvl_q
                                                    if A_lvl_q < A_lvl_q_step
                                                        A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                    else
                                                        A_lvl_i_stop_2 = 0
                                                    end
                                                    phase_stop_11 = min(i_13, A_lvl_i_stop_2)
                                                    if phase_stop_11 >= i_13
                                                        if A_lvl_tbl1[A_lvl_q] < i_13
                                                            A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_13, A_lvl_q, A_lvl_q_step - 1)
                                                        end
                                                        while true
                                                            A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                            if A_lvl_i_2 < phase_stop_11
                                                                A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                A_lvl_q_2 += 1
                                                            else
                                                                phase_stop_13 = min(A_lvl_i_2, phase_stop_11)
                                                                if A_lvl_i_2 == phase_stop_13
                                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                    A_lvl_q_2 += 1
                                                                end
                                                                break
                                                            end
                                                        end
                                                    end
                                                    A_lvl_q = A_lvl_q_step
                                                    B_lvl_q_3 += 1
                                                elseif B_lvl_i_3 == phase_stop_10
                                                    B_lvl_q_3 += 1
                                                elseif A_lvl_i == phase_stop_10
                                                    A_lvl_q = A_lvl_q_step
                                                end
                                                k = phase_stop_10 + 1
                                            end
                                        end
                                    end
                                end
                            end
                        Ct_lvl_2_val = val_4
                        A_lvl_ptr = A_lvl_ptr_3
                        A_lvl_tbl1 = A_lvl_tbl1_3
                        A_lvl_tbl2 = A_lvl_tbl2_3
                        A_lvl_val = val_5
                        B_lvl_ptr = B_lvl_ptr_3
                        B_lvl_tbl1 = B_lvl_tbl1_3
                        B_lvl_tbl2 = B_lvl_tbl2_3
                        B_lvl_val = val_6
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_19 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_19
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_19
                            val_7 = Ct_lvl_2_val
                            Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                            A_lvl_ptr_4 = A_lvl_ptr
                            A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                            A_lvl_tbl1_4 = A_lvl_tbl1
                            A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                            A_lvl_tbl2_4 = A_lvl_tbl2
                            A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                            val_8 = A_lvl_val
                            A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                            B_lvl_ptr_4 = B_lvl_ptr
                            B_lvl_tbl1_4 = B_lvl_tbl1
                            B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                            B_lvl_tbl2_4 = B_lvl_tbl2
                            val_9 = B_lvl_val
                            B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                            Threads.@threads for i_20 = 1:Threads.nthreads()
                                    phase_start_22 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_20), Threads.nthreads()))
                                    phase_stop_24 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_20, Threads.nthreads()))
                                    if phase_stop_24 >= phase_start_22
                                        for i_23 = phase_start_22:phase_stop_24
                                            Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_23
                                            A_lvl_q = A_lvl_ptr[1]
                                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                            if A_lvl_q < A_lvl_q_stop
                                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                            else
                                                A_lvl_i_stop = 0
                                            end
                                            B_lvl_q_3 = B_lvl_q
                                            if B_lvl_q < B_lvl_q_step
                                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                            else
                                                B_lvl_i_stop_3 = 0
                                            end
                                            phase_stop_25 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                            if phase_stop_25 >= 1
                                                k = 1
                                                if A_lvl_tbl2[A_lvl_q] < 1
                                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                if B_lvl_tbl1[B_lvl_q] < 1
                                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                                end
                                                while k <= phase_stop_25
                                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                    A_lvl_q_step = A_lvl_q
                                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                    end
                                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                    phase_stop_26 = min(B_lvl_i_3, A_lvl_i, phase_stop_25)
                                                    if A_lvl_i == phase_stop_26 && B_lvl_i_3 == phase_stop_26
                                                        B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                                        A_lvl_q_4 = A_lvl_q
                                                        if A_lvl_q < A_lvl_q_step
                                                            A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                        else
                                                            A_lvl_i_stop_4 = 0
                                                        end
                                                        phase_stop_27 = min(i_23, A_lvl_i_stop_4)
                                                        if phase_stop_27 >= i_23
                                                            if A_lvl_tbl1[A_lvl_q] < i_23
                                                                A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_23, A_lvl_q, A_lvl_q_step - 1)
                                                            end
                                                            while true
                                                                A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                                if A_lvl_i_4 < phase_stop_27
                                                                    A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                    A_lvl_q_4 += 1
                                                                else
                                                                    phase_stop_29 = min(A_lvl_i_4, phase_stop_27)
                                                                    if A_lvl_i_4 == phase_stop_29
                                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                        A_lvl_q_4 += 1
                                                                    end
                                                                    break
                                                                end
                                                            end
                                                        end
                                                        A_lvl_q = A_lvl_q_step
                                                        B_lvl_q_3 += 1
                                                    elseif B_lvl_i_3 == phase_stop_26
                                                        B_lvl_q_3 += 1
                                                    elseif A_lvl_i == phase_stop_26
                                                        A_lvl_q = A_lvl_q_step
                                                    end
                                                    k = phase_stop_26 + 1
                                                end
                                            end
                                        end
                                    end
                                end
                            Ct_lvl_2_val = val_7
                            A_lvl_ptr = A_lvl_ptr_4
                            A_lvl_tbl1 = A_lvl_tbl1_4
                            A_lvl_tbl2 = A_lvl_tbl2_4
                            A_lvl_val = val_8
                            B_lvl_ptr = B_lvl_ptr_4
                            B_lvl_tbl1 = B_lvl_tbl1_4
                            B_lvl_tbl2 = B_lvl_tbl2_4
                            B_lvl_val = val_9
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.5786578146202624, 0.0, 0.3202961159483594, 0.3207279869105304, 0.5035217854841559, 0.0, 0.013671076975665627, 0.01669925591794789, 0.0, 0.0, 0.0, 0.5652457771225854, 0.0, 0.09766762955114001, 0.2831455624824939, 0.0, 1.0556185392068085, 0.2068017763866623, 0.0, 0.15942131380345745, 0.005607444973383372, 0.0, 0.056687675717707615, 0.2535497922885842, 0.4637407985590488, 0.22387274550179712, 0.5454655738973408, 0.08490666489615803, 0.3556465582001688, 0.0, 0.0, 0.31186727366054, 0.6972638697010188, 0.0, 0.0, 0.009518501694028625, 0.0, 0.5833334701399113, 0.6244214908493986, 0.0, 0.26168041250093527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0131047746782154, 0.0, 0.6656645247350605, 0.0, 0.0, 0.0769882955934405, 0.0, 0.0, 0.34004774503974494, 0.08053504092577264, 0.006982581834800098, 0.5446249720805942, 0.0, 0.0, 0.31025177039320695, 0.2638902653915397, 0.0, 0.0, 0.0, 0.0, 0.2008136945182758, 0.0, 0.0, 0.19041992572397343, 0.05903622381609576, 0.0, 0.0589978949008293, 0.05133054295704808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7141967536140789, 0.0, 0.11331087789790419, 0.0, 0.0, 0.13904571220904566, 0.16685503671570054, 0.0, 0.1461222249815685, 0.0, 0.0, 0.0, 0.1624667486179013, 0.0, 0.0, 0.0001466632220376543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040061564188380784, 0.0, 0.0, 0.05925661356360367, 0.0, 0.20052213796576485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322273764299389, 0.0, 0.07284319524978862, 0.0, 0.21698248889777863, 0.0, 0.22616177063294415, 0.0, 0.0, 0.0, 0.0, 0.52849490550171, 0.0, 0.71926878469886, 0.0, 0.6501927607213651, 0.0030355649865830615, 0.37799680598211977, 0.0, 0.0007078975665940506, 0.09351646752064424, 0.05681500695663011, 0.0, 0.20243859396970953, 0.0628704495708815, 0.001556209278473695, 0.0, 0.0, 0.0, 0.0, 0.0027171741525499, 0.0, 0.0, 0.0, 0.07038911039656341, 0.049709343960620045, 0.0, 0.018852918431012597, 0.26140762404567164, 0.049374687944063446, 0.0, 0.0, 0.5682508160039592, 0.08397693763382687, 0.0, 0.0, 1.1395457189674745, 0.10207861893624984, 0.006346754524020049, 0.07139718683099765, 0.0, 0.4257292397317542, 0.0, 0.0, 0.003459642976589088, 0.00011827788909935122, 0.29669071600135444, 0.0, 0.04645302583039929, 0.6403581026228157, 0.0, 0.0, 0.4035906657629842, 0.0, 0.0, 0.031770473502227184, 0.0, 0.10177861753458611, 0.08984803025006428, 0.2696383585775038, 0.0, 0.0, 0.0, 0.0, 0.4020058229022269, 0.8537152750348289, 0.27466570696380027, 0.0, 0.9014511503031993, 0.0, 0.0, 0.0, 0.3588364621034526, 0.0, 0.10358336916612662, 0.0, 0.8253783539224127, 0.003096290011755601, 0.3727209618097055, 0.0, 0.0, 0.0, 0.08512247762765326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016669318756259504, 0.0, 0.0, 0.9038241621401286, 0.23981242371494071, 0.0, 0.0, 0.0, 0.10303433366133424, 0.0, 0.0, 4.317142647672722e-5, 0.0, 0.07840647389573854, 0.0, 0.0, 0.0, 0.0, 0.36164895718336953, 0.011697025915496142, 0.0, 0.0, 0.0, 0.0, 0.001969151291048087, 0.0, 0.0016085698018090215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8640055140280944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10961290316901336, 0.0, 0.0, 0.0, 0.34012752342022284, 0.0, 0.09000159029348583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38387258660557405, 0.0, 0.0, 0.0, 0.04942864149427501, 0.0, 0.9641925530766522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618638919487994, 0.0, 0.0, 0.1434695556565637, 0.3651050198592113, 0.0, 0.04210320606021404, 0.5803955429188099, 0.0, 0.0, 0.36579879697476825, 0.4517875751113323, 0.0, 0.0, 0.0, 0.597783133294766, 0.0, 0.0, 0.6329135233850276, 0.0, 0.002597015658553236, 0.2174699638827603, 0.39061652165480276, 0.765918958416278, 0.0, 0.016481521625833693, 0.28751000269430316, 0.0, 0.1647131064041664, 0.0, 0.4521970394725687, 0.0, 0.0, 0.11039007420645473, 0.0, 0.0, 0.0, 0.902497226885166, 0.7436286750029288, 0.09842900387294973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017337381605838167, 0.0, 0.48184280820859876, 0.0, 0.0, 0.4182604044398821, 0.05413499724631636, 0.00395203096164986, 0.49703533424495255, 0.0, 0.0, 0.0, 0.43461516165530706, 0.0, 0.0, 0.2097986260899648, 0.0, 0.0, 0.0, 0.0032389406325184205, 0.11624028110212369, 0.0, 0.23514374437795085, 0.0, 0.013757851512121493, 0.0, 0.23992048040279412, 0.32911722925956555, 0.0, 0.18863648593265903, 0.5965040702112832, 0.0, 0.0, 0.006607346447861224, 0.005821424904675781, 0.2242736217811627, 0.0, 0.0, 0.02743682303358625, 0.03021510122691055, 0.4109976396191596, 0.016694351333046, 0.0, 0.0, 0.15588266372439724, 0.0, 0.7589538506473881, 0.0, 0.0, 0.9157838182946224, 0.07079903450052254, 0.0, 0.0, 0.0, 0.8133345120890082, 0.19376473666562866, 0.0, 0.0, 0.24554349589597185, 0.2326206471524158, 0.5829196459370383, 0.0, 0.344078222468009, 0.0, 0.5927124546739914, 0.21206748875282805, 0.5013588717575729, 0.1507046170639337, 0.0, 0.2922067750640437, 0.9112630304460252, 0.0, 0.42296978570223137, 0.0, 0.0, 0.0, 0.0, 0.47847449991115903, 0.0, 0.0, 0.0, 0.0, 0.02922391861250235, 0.003575617433634187, 0.0, 0.0, 0.18000379265062824, 0.0, 0.0, 0.0, 0.020223410318598516, 0.0, 0.0, 0.0, 0.0, 0.1194607408090099, 0.0, 0.18567470153771173, 0.015493204406064897, 0.0, 0.0, 0.22675090423473912, 0.0, 0.6338841242698132, 0.5245326238847832, 0.0019166419799919094, 0.6594541233567529, 0.0, 0.005139571264149575, 0.0, 0.0, 0.0, 0.014894820580065271, 0.0, 1.2034959876942206, 0.0, 0.25665804266856174, 0.012594729973842587, 0.0, 0.011446343678364038, 0.0, 0.0, 0.02279435489937408, 0.025102532455875536, 0.0, 0.0, 0.0, 0.0, 0.1307674017372415, 0.5572422675871412, 0.20860522647402835, 0.3439153754178085, 0.0, 0.7682359770495442, 0.05881943098741484, 0.0, 0.0, 0.7560476592821442, 0.06967644285195858, 0.0, 0.04321641535911349, 0.0, 0.0, 0.0, 0.8024673537053417, 0.0, 0.0, 0.0, 0.0, 0.1761844509232577, 0.8168042507595197, 0.0, 0.0, 0.0, 0.5887168313525647, 0.0, 0.0, 0.4050160345946778, 0.0, 0.28424121144843517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04314478705768561, 0.17729851568072083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06445720856859194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10331544984256105, 0.2490312779322865, 0.0, 0.24280852181294071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5198374016631779, 0.0, 0.0, 0.0, 0.13645064069986682, 0.0, 0.24758012015088376, 0.5314044104438821, 0.0, 0.0, 0.3110470576055099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02359980206981429, 0.36163373919282166, 0.0, 0.0, 0.4835792742792758, 0.0, 0.3524294596638372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27655502261887766, 0.0, 0.0, 0.0, 0.0, 0.22117286156450722, 0.0, 0.15521963759663626, 0.0, 0.0, 0.0, 0.0, 0.021723812939992326, 0.02392358642299197, 0.0, 0.9811990708246294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4965569454339231, 0.08530918757868192, 0.0, 0.07823884141505981, 0.08129763345109173, 0.8580687524263778, 0.6125638634435169, 0.7792197114170356, 0.17406349022985984, 0.0, 0.7428281837408045, 0.0, 0.07932414385265583, 0.46154167819945197, 0.0, 0.5289001614381607, 0.0, 0.8287876866571131, 0.1679099089089469, 0.695722986230781, 0.0, 0.010707260605614142, 0.014687966352699852, 0.03846916856579124, 0.6678999803007167, 0.8946423775406338, 0.0, 0.0, 0.6928842432378984, 0.0, 0.8291172549334254, 0.0, 0.036214437271524916, 0.0, 0.6493274982169268, 0.0, 0.0, 0.0, 0.0, 0.022863259627981244, 0.7335275809594394, 0.03647235770741211, 0.0, 0.287070580153256, 0.13431771500769504, 0.14856735628547443, 0.15781940486580828, 0.0, 0.0, 0.323980207489089, 0.0, 0.02667757509153305, 0.33154611696012287, 0.008340998981572286, 0.0, 0.1964137723963185, 0.0, 0.18369526317696738, 0.0, 0.36991237719570497, 0.0, 0.0, 0.060663484669780686, 0.0, 0.0, 0.10293074255327075, 0.9555336304557553, 0.0, 0.2500171656161189, 0.5342857393564834, 0.17546263843294155, 0.0, 0.35442104566615373, 0.0, 0.0, 0.0, 0.0, 0.17621149415330922, 0.6121951999020001, 0.14104370661074167, 0.0, 0.03700642443953683, 0.5101360635898259, 0.0, 0.0, 0.398419677876043, 0.0, 0.0, 0.0, 0.23862742072997933, 0.0, 0.06314351493041778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32025466250143747, 0.0, 0.0, 0.0, 0.25412006584310015, 0.0, 0.2693181789862389, 0.0, 0.2858641430477511, 0.0, 0.12448957171647013, 0.0, 0.6764603455612473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629531631679027, 0.008402105093687509, 0.1478058101242069, 0.005053168588900645, 0.0, 0.30372648283729076, 0.003980754378397801, 0.0, 0.0, 0.0, 0.0, 0.07450559902388645, 0.019687537166852037, 0.0, 0.08244653582028545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16209616805705127, 0.0, 0.08979346385777931, 0.06518743281502334, 0.21315534710850095, 0.08369413937188341, 0.1394160455900761, 0.5610626715103558, 0.0, 0.0, 0.13968567626607642, 0.0, 0.0, 0.0, 0.0, 0.01924679403964147, 0.0, 0.0, 0.0, 0.0, 0.616722369104707, 0.0, 0.0, 0.5466375681050827, 0.0, 0.0, 0.013987945284851467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09368066064257337, 0.0, 0.24818473838609467, 0.04865531902212218, 0.0, 0.009894965642192768, 0.0, 0.45825677816644195, 0.7857899124906229, 0.25281208870305677, 0.0, 0.8251354193653254, 0.0, 0.6275782447904167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7597076021322064, 0.4559884064545227, 0.3430656338577527, 0.32001374263313714, 0.2977084759378876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26332513624077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07361684952632414, 0.0, 0.0, 0.0, 0.5420044017413929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5785225932672249, 0.0, 0.0, 0.0, 0.6899231282082093, 0.33897374575165645, 0.4841896839083132, 0.0, 0.0, 0.0, 0.0, 0.6240541831707288, 0.0, 0.0, 0.5531361892215293, 0.4547991804243185, 0.0, 0.100152739355421, 0.0, 0.2440837061302026, 0.0, 0.0, 0.0, 0.0, 0.12076927556310874, 0.0, 0.0, 0.3415398112751411, 0.0, 0.0, 0.0, 0.010012600500133058, 0.0, 0.10122097549537463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6350391173534848, 0.0, 0.0, 0.5362493708751273, 0.3870491592555651, 0.0, 0.0, 0.011769944241680865, 0.3142045963597273, 0.0, 0.30124773979598957, 0.0, 0.3235765421156834, 0.0, 0.541761414379215, 0.0, 0.0, 0.8318031269227326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.655176286023573, 0.0, 0.0, 0.12998028512957016, 0.09284961824757046, 0.5535451825358659, 0.6996061073192734, 0.06205996989121698, 0.0, 0.0, 0.0, 0.008692259029504977, 0.0, 0.08787316923443415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5512977874061133, 0.0, 0.06274188232221303, 0.0860678272807259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7913396090809787, 0.26152280681975265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028664478181671504, 0.0009799779903315728, 0.0032348889210802386, 0.0, 0.11837934340514084, 0.4864662292788164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07382213914734657, 0.0, 0.0, 0.0, 0.17685571185867954, 0.2510513607906149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019118999997271302, 0.0, 0.04133793381575315, 0.2834737624180827, 0.6832843821792778, 0.0, 0.6662105748014928, 0.0, 0.5326269406399959, 0.0, 0.0, 0.0, 0.0, 0.10672810444069859, 0.0, 0.07123750254807154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007981914293001519, 0.10075857550012479, 0.009540391703188681, 0.0, 0.11580721042791553, 0.0, 0.0, 0.17856228523566461, 0.00048020843909893406, 0.0, 0.197593765283525, 0.0, 0.0, 0.0, 0.6194557197663932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21520162666608084, 0.1562300971282056, 0.0, 0.0592523063663964, 0.0, 0.18612758103797813, 0.0, 0.2544272402257203, 0.15422821911002763, 0.0012917517157272594, 0.0, 0.0, 0.14907655404346837, 0.09429642888622711, 0.0, 0.0, 0.0, 0.0, 0.09600808583182174, 0.0, 0.005856583784053075, 0.08156012032053195, 0.09312148266647201, 0.0322184865015818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03641255600507808, 0.0, 0.09646644914865622, 0.6107192924560144, 0.0, 0.0008311989920553221, 0.04768463204338608, 0.008402889219987731, 0.30542717141970227, 0.09826504505325136, 0.08476742117805344, 0.35700707759139916, 0.0, 0.052717960159591244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29528928831604634, 0.0, 0.18118798681716172, 0.047489656233823854, 0.07375616702811215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15842644268884615, 0.005416265593171256, 0.0, 0.0, 0.0, 0.06326712126451656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22847169102573353, 0.0, 0.11955753824812076, 0.0, 0.0, 0.0, 0.08074664695989245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0029119331378805115, 0.0, 0.0, 0.1953274033599059, 0.0, 0.0, 0.0, 0.48520999511490304, 0.0, 0.0, 0.0, 0.0, 0.13603276168063752, 0.0, 0.06155663979875702, 0.0, 0.0, 0.0, 0.19100951475155065, 0.0, 0.05054327834442013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21557595738397023, 0.0, 0.0, 0.2988625665604049, 0.02775823823873608, 0.0, 0.5414732387378444, 0.0, 0.1751125450084881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7653173403797493, 0.011610920930129028, 0.0, 0.6690009447860032, 0.007717112212206315, 0.0, 0.0, 0.0, 0.0, 0.0949800986519104, 0.0, 0.01759104522847652, 0.0272063292239745, 0.0, 0.18672851022958098, 0.14592398686801408, 0.0, 0.0, 0.06111532732066789, 0.0, 0.012109927581814974, 0.0, 0.3464253043638218, 0.014416979955844242, 0.0, 0.0, 0.004751074128394563, 0.0814923248235591, 0.960719872887566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029410227635468144, 0.3902617128196832, 0.0, 0.0, 0.0, 0.0, 0.03936155946785215, 0.0, 0.0, 0.0, 0.0, 0.03226521554976169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029868187491618223, 0.0, 0.007848954300217155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02618395857766568, 0.0, 0.0, 0.0, 0.02729344001455739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16043383601301778, 0.0, 0.08114240967089056, 0.0, 0.12944151616666955, 0.0, 0.0, 0.8424042898437758, 0.0, 0.0, 0.0, 0.0, 0.04323489183997365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2997198089695268, 0.0, 0.0, 0.09877179787471602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36530436236505814, 0.0, 0.0, 0.0, 0.0, 0.6114198560066337, 0.538693529249165, 0.0, 0.0, 0.0, 0.014312907460573414, 0.015762245768879076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03693357747227013, 0.0, 0.0, 0.5249268945825, 0.0, 0.0, 0.16471382065012125, 0.0, 0.0, 0.0, 0.304090416701445, 0.48915218766248414, 0.0, 0.020376509279081044, 0.0, 0.11062878301178729, 0.26154278602954106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1338990979320024, 0.0, 0.12169019076516314, 0.0, 0.0, 0.0, 0.5524220216872981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13426647560262422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05161008110067911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007893769925822126, 0.008693100403012733, 0.0, 1.169538837435482, 0.0, 0.5817658012805581, 0.3172103076471354, 0.0, 0.22838627747698767, 0.0, 0.10226945824142554, 0.0, 0.020369387834492953, 0.0, 0.20675490808600527, 0.48677742001957014, 0.6262431249386917, 0.151645446757169, 0.20817481578766972, 0.0, 0.0, 0.0668476153746235, 0.5758263086091524, 0.4536026680375212, 0.09887690089373365, 0.018895630454912823, 0.0, 0.06101333098633492, 0.38664812220872247, 0.0, 0.0, 0.7304510924229297, 0.030046419431745734, 0.0, 1.1003509629444073, 0.5194953755737197, 1.1578838988668234, 0.48875095960339066, 0.0, 0.1128462605244655, 0.0, 0.0, 0.0, 0.4791947947301635, 0.0, 0.03259627779739397, 0.10028189990101041, 0.029465846845003113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22859113464308234, 0.0, 0.11646855789532944, 0.12693945289885786, 0.0, 0.0, 0.20330790896109577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873449680464739, 0.0, 0.0, 0.06173899342973636, 0.0, 0.0, 0.04476882030066193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04375496463125991, 0.38217838780949126, 0.336719559414533, 0.04092456729054698, 0.0, 0.04229882731958149, 0.0, 0.0, 0.0, 0.1452994629839798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0184335582446928, 0.0, 0.0, 0.0, 0.057199110071214684, 0.0, 0.14103517741623545, 0.03340505872611428, 0.0, 0.0, 0.0, 0.05811339385405451, 0.0, 0.0, 0.0, 0.0, 0.044222795803071285, 0.0, 0.06455569991448866, 0.0, 0.0, 0.05037647535437417, 0.008312394942553907, 0.0, 0.1621478774157853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005416039933812771, 0.0, 0.0, 0.0, 0.0398756195493532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05075809733341722, 0.0, 0.03562215281502755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19049409924372604, 0.0, 0.0, 0.20255925674743036, 0.0, 0.0, 0.0, 0.0, 0.11222926185446927, 0.0, 0.22599925727813394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212734324380878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21653477423901774, 0.0, 0.0, 0.008644589577152558, 0.009519948749861491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022306831770080617, 0.0, 0.0, 0.003074570476841778, 0.0, 0.008145346800616094, 0.0, 0.0, 0.0, 0.08511345922427967, 0.18366197461769765, 0.025789383308915437, 0.008297215015175531, 0.0, 0.09184984081220632, 0.0668166427534811, 0.15796441417080423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024933369902885204, 0.0, 0.011259308615493588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02160071316022016, 0.0, 0.0, 0.0, 0.1015273549658925, 0.0, 0.3722773110385471, 0.0, 0.0, 0.0, 0.005704132382790829, 0.576786252698806, 0.6048982987919145, 0.3404333765031976, 0.0, 0.1776491403162125, 0.3619951063590594, 0.0, 0.0, 0.0, 0.0, 0.20056572202110787, 0.0, 0.4038849000985208, 0.0, 0.07292911426252524, 0.0, 0.0, 0.0, 0.0, 0.3254810866068793, 0.0, 0.0, 0.0, 0.0486152336987337, 0.0, 0.38697085430573647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7532037777522111, 0.0, 0.0, 0.2947709821219489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008564738540478935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2647016620516834, 0.0, 0.0, 0.5486174586047213, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)

