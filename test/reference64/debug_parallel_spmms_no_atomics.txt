julia> @finch begin
        CR .= 0
        for i = _
            for j = _
                for k = _
                    CR[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(CR = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            phase_start_2 = max(1, 1 + fld(A_lvl.shape[1] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                for i_7 = phase_start_2:phase_stop_2
                    B_lvl_q = B_lvl_ptr[1]
                    B_lvl_q_stop = B_lvl_ptr[1 + 1]
                    if B_lvl_q < B_lvl_q_stop
                        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                    else
                        B_lvl_i_stop = 0
                    end
                    phase_stop_3 = min(B_lvl.shape[2], B_lvl_i_stop)
                    if phase_stop_3 >= 1
                        if B_lvl_tbl2[B_lvl_q] < 1
                            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        while true
                            B_lvl_i = B_lvl_tbl2[B_lvl_q]
                            B_lvl_q_step = B_lvl_q
                            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                            end
                            if B_lvl_i < phase_stop_3
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_5 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_5 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_5
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_6 = min(B_lvl_i_2, phase_stop_5, A_lvl_i)
                                        if A_lvl_i == phase_stop_6 && B_lvl_i_2 == phase_stop_6
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_7 = min(i_7, A_lvl_i_stop_2)
                                            if phase_stop_7 >= i_7
                                                if A_lvl_tbl1[A_lvl_q] < i_7
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_7
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_9 = min(A_lvl_i_2, phase_stop_7)
                                                        if A_lvl_i_2 == phase_stop_9
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_6
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_6
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_6 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            else
                                phase_stop_14 = min(B_lvl_i, phase_stop_3)
                                if B_lvl_i == phase_stop_14
                                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_14
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_15 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_15 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_15
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_16 = min(B_lvl_i_2, A_lvl_i, phase_stop_15)
                                            if A_lvl_i == phase_stop_16 && B_lvl_i_2 == phase_stop_16
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_17 = min(i_7, A_lvl_i_stop_4)
                                                if phase_stop_17 >= i_7
                                                    if A_lvl_tbl1[A_lvl_q] < i_7
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_17
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_19 = min(A_lvl_i_4, phase_stop_17)
                                                            if A_lvl_i_4 == phase_stop_19
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_16
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_16
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_16 + 1
                                        end
                                    end
                                    B_lvl_q = B_lvl_q_step
                                end
                                break
                            end
                        end
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    for i_4 = 1:A_lvl.shape[1]
        val = Ct_lvl_2_val
        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
        B_lvl_ptr_2 = B_lvl_ptr
        B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
        B_lvl_tbl1_2 = B_lvl_tbl1
        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
        B_lvl_tbl2_2 = B_lvl_tbl2
        B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
        val_2 = B_lvl_val
        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
        A_lvl_ptr_2 = A_lvl_ptr
        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
        A_lvl_tbl1_2 = A_lvl_tbl1
        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
        A_lvl_tbl2_2 = A_lvl_tbl2
        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
        val_3 = A_lvl_val
        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
        Threads.@threads for i_5 = 1:Threads.nthreads()
                B_lvl_q = B_lvl_ptr[1]
                B_lvl_q_stop = B_lvl_ptr[1 + 1]
                if B_lvl_q < B_lvl_q_stop
                    B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                else
                    B_lvl_i_stop = 0
                end
                phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_5 + -1), Threads.nthreads()))
                phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_5, Threads.nthreads()))
                if phase_stop_2 >= phase_start_2
                    if B_lvl_tbl2[B_lvl_q] < phase_start_2
                        B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    while true
                        B_lvl_i = B_lvl_tbl2[B_lvl_q]
                        B_lvl_q_step = B_lvl_q
                        if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                            B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        if B_lvl_i < phase_stop_2
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_4, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_4
                                            if A_lvl_tbl1[A_lvl_q] < i_4
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        else
                            phase_stop_13 = min(B_lvl_i, phase_stop_2)
                            if B_lvl_i == phase_stop_13
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_4, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_4
                                                if A_lvl_tbl1[A_lvl_q] < i_4
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            end
                            break
                        end
                    end
                end
            end
        Ct_lvl_2_val = val
        B_lvl_ptr = B_lvl_ptr_2
        B_lvl_tbl1 = B_lvl_tbl1_2
        B_lvl_tbl2 = B_lvl_tbl2_2
        B_lvl_val = val_2
        A_lvl_ptr = A_lvl_ptr_2
        A_lvl_tbl1 = A_lvl_tbl1_2
        A_lvl_tbl2 = A_lvl_tbl2_2
        A_lvl_val = val_3
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        for i_6 = 1:A_lvl.shape[1]
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_6
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_6, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_6
                                            if A_lvl_tbl1[A_lvl_q] < i_6
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_6, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                        end
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_13 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_13
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                            for i_8 = 1:A_lvl.shape[1]
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_8
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_8, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_8
                                                if A_lvl_tbl1[A_lvl_q] < i_8
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_8, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    B_lvl_q = B_lvl_ptr[1]
    B_lvl_q_stop = B_lvl_ptr[1 + 1]
    if B_lvl_q < B_lvl_q_stop
        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
    else
        B_lvl_i_stop = 0
    end
    phase_stop = min(B_lvl.shape[2], B_lvl_i_stop)
    if phase_stop >= 1
        if B_lvl_tbl2[B_lvl_q] < 1
            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
        end
        while true
            B_lvl_i = B_lvl_tbl2[B_lvl_q]
            B_lvl_q_step = B_lvl_q
            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
            end
            if B_lvl_i < phase_stop
                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                val = Ct_lvl_2_val
                Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                B_lvl_tbl1_2 = B_lvl_tbl1
                B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                B_lvl_tbl2_2 = B_lvl_tbl2
                val_2 = B_lvl_val
                B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                A_lvl_ptr_2 = A_lvl_ptr
                A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                A_lvl_tbl1_2 = A_lvl_tbl1
                A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                A_lvl_tbl2_2 = A_lvl_tbl2
                A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                val_3 = A_lvl_val
                A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                Threads.@threads for i_9 = 1:Threads.nthreads()
                        phase_start_6 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_9), Threads.nthreads()))
                        phase_stop_7 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_9, Threads.nthreads()))
                        if phase_stop_7 >= phase_start_6
                            for i_12 = phase_start_6:phase_stop_7
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_12
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_8 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_8 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_8
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_9 = min(B_lvl_i_2, phase_stop_8, A_lvl_i)
                                        if A_lvl_i == phase_stop_9 && B_lvl_i_2 == phase_stop_9
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_10 = min(i_12, A_lvl_i_stop_2)
                                            if phase_stop_10 >= i_12
                                                if A_lvl_tbl1[A_lvl_q] < i_12
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_12, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_10
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_12 = min(A_lvl_i_2, phase_stop_10)
                                                        if A_lvl_i_2 == phase_stop_12
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_9
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_9
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_9 + 1
                                    end
                                end
                            end
                        end
                    end
                Ct_lvl_2_val = val
                B_lvl_tbl1 = B_lvl_tbl1_2
                B_lvl_tbl2 = B_lvl_tbl2_2
                B_lvl_val = val_2
                A_lvl_ptr = A_lvl_ptr_2
                A_lvl_tbl1 = A_lvl_tbl1_2
                A_lvl_tbl2 = A_lvl_tbl2_2
                A_lvl_val = val_3
                B_lvl_q = B_lvl_q_step
            else
                phase_stop_18 = min(B_lvl_i, phase_stop)
                if B_lvl_i == phase_stop_18
                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_18
                    val_4 = Ct_lvl_2_val
                    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                    B_lvl_tbl1_3 = B_lvl_tbl1
                    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                    B_lvl_tbl2_3 = B_lvl_tbl2
                    val_5 = B_lvl_val
                    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                    A_lvl_ptr_3 = A_lvl_ptr
                    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                    A_lvl_tbl1_3 = A_lvl_tbl1
                    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                    A_lvl_tbl2_3 = A_lvl_tbl2
                    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                    val_6 = A_lvl_val
                    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                    Threads.@threads for i_19 = 1:Threads.nthreads()
                            phase_start_21 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_19), Threads.nthreads()))
                            phase_stop_23 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_19, Threads.nthreads()))
                            if phase_stop_23 >= phase_start_21
                                for i_22 = phase_start_21:phase_stop_23
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_22
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_24 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_24 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_24
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_25 = min(B_lvl_i_2, A_lvl_i, phase_stop_24)
                                            if A_lvl_i == phase_stop_25 && B_lvl_i_2 == phase_stop_25
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_26 = min(i_22, A_lvl_i_stop_4)
                                                if phase_stop_26 >= i_22
                                                    if A_lvl_tbl1[A_lvl_q] < i_22
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_22, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_26
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_28 = min(A_lvl_i_4, phase_stop_26)
                                                            if A_lvl_i_4 == phase_stop_28
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_25
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_25
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_25 + 1
                                        end
                                    end
                                end
                            end
                        end
                    Ct_lvl_2_val = val_4
                    B_lvl_tbl1 = B_lvl_tbl1_3
                    B_lvl_tbl2 = B_lvl_tbl2_3
                    B_lvl_val = val_5
                    A_lvl_ptr = A_lvl_ptr_3
                    A_lvl_tbl1 = A_lvl_tbl1_3
                    A_lvl_tbl2 = A_lvl_tbl2_3
                    A_lvl_val = val_6
                    B_lvl_q = B_lvl_q_step
                end
                break
            end
        end
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        val_4 = Ct_lvl_2_val
                        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                        A_lvl_ptr_3 = A_lvl_ptr
                        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                        A_lvl_tbl1_3 = A_lvl_tbl1
                        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                        A_lvl_tbl2_3 = A_lvl_tbl2
                        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                        val_5 = A_lvl_val
                        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                        B_lvl_ptr_3 = B_lvl_ptr
                        B_lvl_tbl1_3 = B_lvl_tbl1
                        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                        B_lvl_tbl2_3 = B_lvl_tbl2
                        val_6 = B_lvl_val
                        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                        Threads.@threads for i_10 = 1:Threads.nthreads()
                                phase_start_7 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_10), Threads.nthreads()))
                                phase_stop_8 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_10, Threads.nthreads()))
                                if phase_stop_8 >= phase_start_7
                                    for i_13 = phase_start_7:phase_stop_8
                                        Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_13
                                        A_lvl_q = A_lvl_ptr[1]
                                        A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                        if A_lvl_q < A_lvl_q_stop
                                            A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                        else
                                            A_lvl_i_stop = 0
                                        end
                                        B_lvl_q_3 = B_lvl_q
                                        if B_lvl_q < B_lvl_q_step
                                            B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                        else
                                            B_lvl_i_stop_3 = 0
                                        end
                                        phase_stop_9 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                        if phase_stop_9 >= 1
                                            k = 1
                                            if A_lvl_tbl2[A_lvl_q] < 1
                                                A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            if B_lvl_tbl1[B_lvl_q] < 1
                                                B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                            end
                                            while k <= phase_stop_9
                                                A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                A_lvl_q_step = A_lvl_q
                                                if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                    A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                phase_stop_10 = min(B_lvl_i_3, phase_stop_9, A_lvl_i)
                                                if A_lvl_i == phase_stop_10 && B_lvl_i_3 == phase_stop_10
                                                    B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                                    A_lvl_q_2 = A_lvl_q
                                                    if A_lvl_q < A_lvl_q_step
                                                        A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                    else
                                                        A_lvl_i_stop_2 = 0
                                                    end
                                                    phase_stop_11 = min(i_13, A_lvl_i_stop_2)
                                                    if phase_stop_11 >= i_13
                                                        if A_lvl_tbl1[A_lvl_q] < i_13
                                                            A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_13, A_lvl_q, A_lvl_q_step - 1)
                                                        end
                                                        while true
                                                            A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                            if A_lvl_i_2 < phase_stop_11
                                                                A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                A_lvl_q_2 += 1
                                                            else
                                                                phase_stop_13 = min(A_lvl_i_2, phase_stop_11)
                                                                if A_lvl_i_2 == phase_stop_13
                                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                    A_lvl_q_2 += 1
                                                                end
                                                                break
                                                            end
                                                        end
                                                    end
                                                    A_lvl_q = A_lvl_q_step
                                                    B_lvl_q_3 += 1
                                                elseif B_lvl_i_3 == phase_stop_10
                                                    B_lvl_q_3 += 1
                                                elseif A_lvl_i == phase_stop_10
                                                    A_lvl_q = A_lvl_q_step
                                                end
                                                k = phase_stop_10 + 1
                                            end
                                        end
                                    end
                                end
                            end
                        Ct_lvl_2_val = val_4
                        A_lvl_ptr = A_lvl_ptr_3
                        A_lvl_tbl1 = A_lvl_tbl1_3
                        A_lvl_tbl2 = A_lvl_tbl2_3
                        A_lvl_val = val_5
                        B_lvl_ptr = B_lvl_ptr_3
                        B_lvl_tbl1 = B_lvl_tbl1_3
                        B_lvl_tbl2 = B_lvl_tbl2_3
                        B_lvl_val = val_6
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_19 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_19
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_19
                            val_7 = Ct_lvl_2_val
                            Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                            A_lvl_ptr_4 = A_lvl_ptr
                            A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                            A_lvl_tbl1_4 = A_lvl_tbl1
                            A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                            A_lvl_tbl2_4 = A_lvl_tbl2
                            A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                            val_8 = A_lvl_val
                            A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                            B_lvl_ptr_4 = B_lvl_ptr
                            B_lvl_tbl1_4 = B_lvl_tbl1
                            B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                            B_lvl_tbl2_4 = B_lvl_tbl2
                            val_9 = B_lvl_val
                            B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                            Threads.@threads for i_20 = 1:Threads.nthreads()
                                    phase_start_22 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_20), Threads.nthreads()))
                                    phase_stop_24 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_20, Threads.nthreads()))
                                    if phase_stop_24 >= phase_start_22
                                        for i_23 = phase_start_22:phase_stop_24
                                            Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_23
                                            A_lvl_q = A_lvl_ptr[1]
                                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                            if A_lvl_q < A_lvl_q_stop
                                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                            else
                                                A_lvl_i_stop = 0
                                            end
                                            B_lvl_q_3 = B_lvl_q
                                            if B_lvl_q < B_lvl_q_step
                                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                            else
                                                B_lvl_i_stop_3 = 0
                                            end
                                            phase_stop_25 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                            if phase_stop_25 >= 1
                                                k = 1
                                                if A_lvl_tbl2[A_lvl_q] < 1
                                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                if B_lvl_tbl1[B_lvl_q] < 1
                                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                                end
                                                while k <= phase_stop_25
                                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                    A_lvl_q_step = A_lvl_q
                                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                    end
                                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                    phase_stop_26 = min(B_lvl_i_3, A_lvl_i, phase_stop_25)
                                                    if A_lvl_i == phase_stop_26 && B_lvl_i_3 == phase_stop_26
                                                        B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                                        A_lvl_q_4 = A_lvl_q
                                                        if A_lvl_q < A_lvl_q_step
                                                            A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                        else
                                                            A_lvl_i_stop_4 = 0
                                                        end
                                                        phase_stop_27 = min(i_23, A_lvl_i_stop_4)
                                                        if phase_stop_27 >= i_23
                                                            if A_lvl_tbl1[A_lvl_q] < i_23
                                                                A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_23, A_lvl_q, A_lvl_q_step - 1)
                                                            end
                                                            while true
                                                                A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                                if A_lvl_i_4 < phase_stop_27
                                                                    A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                    A_lvl_q_4 += 1
                                                                else
                                                                    phase_stop_29 = min(A_lvl_i_4, phase_stop_27)
                                                                    if A_lvl_i_4 == phase_stop_29
                                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                        A_lvl_q_4 += 1
                                                                    end
                                                                    break
                                                                end
                                                            end
                                                        end
                                                        A_lvl_q = A_lvl_q_step
                                                        B_lvl_q_3 += 1
                                                    elseif B_lvl_i_3 == phase_stop_26
                                                        B_lvl_q_3 += 1
                                                    elseif A_lvl_i == phase_stop_26
                                                        A_lvl_q = A_lvl_q_step
                                                    end
                                                    k = phase_stop_26 + 1
                                                end
                                            end
                                        end
                                    end
                                end
                            Ct_lvl_2_val = val_7
                            A_lvl_ptr = A_lvl_ptr_4
                            A_lvl_tbl1 = A_lvl_tbl1_4
                            A_lvl_tbl2 = A_lvl_tbl2_4
                            A_lvl_val = val_8
                            B_lvl_ptr = B_lvl_ptr_4
                            B_lvl_tbl1 = B_lvl_tbl1_4
                            B_lvl_tbl2 = B_lvl_tbl2_4
                            B_lvl_val = val_9
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.1187145765025676, 0.0, 0.16555522612551515, 0.0, 0.0, 0.0, 0.0, 0.43509113842452285, 0.0, 0.0, 0.25672403787937165, 0.43862663884873543, 0.0, 0.0, 0.3519631419607619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051120283482812334, 0.15945060967882835, 0.42044865267857073, 0.0, 0.019744477387695688, 0.0, 0.0, 0.0, 0.12726604148160792, 0.4480285054137333, 0.0, 0.41393771366257825, 0.0, 0.0, 0.1372243591915985, 0.12863434970716192, 0.0, 0.019238858430486484, 0.0, 0.2371659747040811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39682924637787165, 0.0, 0.8480118921637517, 0.0, 0.0, 0.0195483866997798, 0.0, 0.5990836331247341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2618925497434801, 0.26117339231230247, 0.0, 0.0, 0.16216152735698644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06997554550840408, 0.0, 0.0, 0.002400768013297612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4157511852632345, 0.5793963874059174, 0.0, 0.26436870752857605, 0.4172786501470117, 0.0, 0.0, 0.8079649846339338, 0.0, 0.0, 0.5764550461815096, 0.4229367652966696, 0.05379340446506314, 0.0, 0.0, 0.5795406808621261, 0.5877094760316834, 0.0, 0.0, 0.0, 0.0, 0.284387943824113, 0.0, 0.0, 0.0, 0.035174745039109515, 0.0, 0.0, 0.011970205674471077, 0.0, 0.0, 0.0, 0.0, 0.5436476197350472, 0.920039513761917, 0.0, 0.6198132723204128, 0.16799442509225773, 0.5753026732101696, 0.2043616977009669, 0.5065806869454675, 0.0, 0.0, 0.39160092945826996, 0.0, 0.11054447981865345, 0.0, 0.0, 0.9189729667337664, 0.0, 0.0, 0.6507053761422986, 0.6970188689802168, 0.0, 0.08297492397617155, 0.9062181287136433, 0.0, 0.059530976608982995, 0.012438951345378766, 0.0, 0.0, 0.0, 0.0, 0.2533819740366263, 0.9473531228336374, 0.06450793068804792, 0.0, 0.41573543153630554, 0.0, 0.0, 0.0, 0.7238062468593162, 0.0, 0.0, 0.3590904912393951, 0.07774042001084827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6251886494903025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44684741712517223, 0.0, 0.0, 0.0, 0.0, 0.010812740091707317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8163131959379999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2672156592426391, 0.0, 0.028807779838791864, 0.0, 0.0, 0.0, 0.025506753620224757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022871104613233297, 0.0, 0.6057451127777128, 0.0, 0.0, 0.05122083512724408, 0.0, 0.0, 0.26967234588040656, 0.0, 0.0, 0.6655341287456478, 0.0, 0.41411417571013454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29998038732284904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750566800337324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3426210978919867, 0.3800174489235809, 0.0, 0.6531468239127369, 1.5341196475571879, 0.0, 0.0, 0.5993450019914057, 0.0, 0.0, 0.318944682359523, 0.0, 0.0, 0.0, 1.2766961856974943, 0.0, 0.47028907930153113, 0.46890260973852405, 0.0, 0.2635141940642454, 0.0, 0.06844040704623247, 0.6776383700271937, 0.08344450181255293, 0.0, 0.0, 0.13135428676134797, 0.1357944044209692, 0.0, 0.0, 0.0, 0.38624172924075223, 0.0, 0.0, 0.0, 0.23564395924169773, 0.0, 0.7014291092208349, 0.11139739784790205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008393202836106917, 0.0, 0.22229541093446364, 0.2882110765245937, 0.0, 0.2931292388749959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24423669216579333, 0.0, 0.07507242489058646, 0.0, 0.0, 0.14176191313790465, 0.0, 0.0, 0.0, 0.054753508738442806, 0.11008634170637227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024773126340884036, 0.0, 0.0, 0.38053755501306186, 0.0, 0.6713587667580375, 0.05335137428594376, 0.0, 0.0, 0.009224220899634665, 0.0, 0.07390888522469428, 0.1992308489896435, 0.12678608744717204, 0.0, 0.0546923223511062, 0.11313411705958114, 0.0, 0.0, 0.0, 0.0, 0.05169899432402749, 0.019742405777142896, 0.1769782400741126, 0.0, 0.0, 0.09297789149141053, 0.028906196325416873, 0.0, 0.0, 0.012919011582055164, 0.0, 0.0, 0.3208972845059436, 0.0, 0.0, 0.0046103209297173, 0.0, 0.0, 0.00416876885269193, 0.0729081194704697, 0.0, 0.0, 0.0, 0.07125538498910843, 0.0, 0.0, 0.03513444799266689, 0.0, 0.07540438323786366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04369081060273281, 0.0, 0.0, 0.0, 0.014769980988042226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017283118828420634, 0.006620940647292606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006092931164902776, 0.0, 0.16137232276465496, 0.0, 0.15262637216887753, 0.013645384773351038, 0.16271613196948126, 0.0, 0.0, 0.0, 0.0, 0.17730029672438757, 0.41874765425641397, 0.054497803302564006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045113292307115, 0.27028417756519546, 0.07991567883089672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01798371330728596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5859834957136911, 0.5086687281653502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07646258969830243, 0.0, 0.0, 0.02773130153308066, 0.07708391588594585, 0.0, 0.0, 0.06185373806995992, 0.0, 0.0, 0.033137714842779345, 0.0, 0.0, 0.0, 0.0, 0.028021730318764978, 0.07388933025705045, 0.0, 0.021389015345232583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046371970770837774, 0.04025364462832554, 0.2181921153062336, 0.4335185189335439, 0.0, 0.0, 1.0038009425423415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280152293034966, 0.0, 0.08414972142221414, 0.0, 0.3712598089597713, 0.0, 0.06370844553850769, 0.0, 0.0, 0.0, 0.0, 0.5083497561860121, 0.0, 0.0, 0.0, 0.17350738400022994, 0.0, 0.0, 0.0, 0.0, 0.5680638629882098, 0.4512837677833129, 0.036928112404588626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6736518032785722, 0.0, 0.0, 0.0, 0.0, 0.3438277430889845, 0.1331574579932683, 0.8185600695730958, 0.0, 0.0, 0.017261448593960855, 0.0, 0.5289976863810653, 0.0, 0.0, 0.0, 0.0, 0.13826565194431473, 0.0, 0.12839377709982103, 0.8277070113616852, 0.0, 0.0, 0.3904546499995126, 0.08179569775458351, 0.0, 0.0, 0.0, 0.0, 0.16848803520369499, 0.0, 0.0, 0.005780600674157121, 0.0, 0.0, 0.0, 0.0, 0.042429105563066505, 0.0, 0.0, 0.5671026868317051, 0.5831842436077501, 0.0, 0.0, 0.5203885995071309, 0.0, 0.0, 0.0, 0.0, 0.03279957809056344, 0.20563143706052323, 0.8140555730584957, 0.0, 0.11735707443596549, 0.0, 0.0, 0.0, 0.0, 0.05942421719401875, 0.13531075914415133, 0.0, 0.22862377269710113, 0.0, 0.0, 0.0, 0.0, 0.009783289930470927, 0.0, 0.49666013194599, 0.01297478801242045, 0.004970474495620279, 0.0, 0.0, 0.0, 0.0, 0.18702095525297172, 0.0, 0.0, 0.49027730046536305, 0.0, 0.0, 0.0, 0.3100811795242501, 0.0, 0.5172830310180929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5147075854808417, 0.0, 0.23506445593598685, 0.0, 0.0, 0.0984177418166802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6597667532607603, 0.0, 0.7531258126074596, 0.0, 0.0, 0.0, 0.0, 0.009060495116628974, 0.0, 0.14938403565323904, 0.23931891774764502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17320374473408556, 0.0, 0.0, 0.8859260157921318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2593451028242532, 0.13535058061487634, 0.0, 0.17876385946442425, 0.5885021691653141, 0.4462993508157936, 0.0, 0.38646137613385273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08841279830908562, 0.0, 0.0, 0.4090685041141252, 0.2385779614705672, 0.0, 0.32657075289021537, 0.0, 0.3891842232348578, 0.46695749861500585, 0.0, 0.20033954304824086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6140772326336235, 0.21962331732895995, 0.0, 0.0, 0.21665980127772702, 0.0, 0.10259951624992725, 0.0040997688735825025, 0.0, 0.0, 0.0178257297768441, 0.0025383566681682393, 0.21683531480545457, 0.0, 0.027677402398657985, 0.0, 0.1880826476230884, 0.3419147609793875, 0.03227511522566195, 0.19053492425855037, 0.0, 0.06432217258278244, 0.0026780235214896283, 0.0, 0.0, 0.464125489835237, 0.09967606965443436, 0.0, 0.0, 0.0, 0.011788389508631971, 0.03206041622309702, 0.0, 0.0060682844433003185, 0.0, 0.0, 0.0, 0.010791956772858862, 0.0, 0.0, 0.0, 0.0, 0.4329905527364345, 0.14376890418721155, 0.6930376581272882, 0.0, 0.611818052941564, 0.6291676211651914, 0.0, 0.0, 0.5614206159067703, 0.48216800990329456, 0.0, 0.0, 0.4507229848159907, 0.0, 0.0, 0.8782428778065052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06410974538727675, 0.23291225157991716, 0.08679043179604816, 0.0, 0.0, 0.08995902157278039, 0.8808378297797503, 0.0, 0.0, 0.0, 0.3618017482397369, 0.07709259450646033, 0.0, 0.22347789493902354, 0.0, 1.4151156566032244, 0.0, 0.0, 0.0876553401034732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35023812146064465, 0.10119869206094158, 0.0, 0.0, 0.0, 0.03421091843192662, 0.0, 0.18934530571059222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040031965441735276, 0.015335731346610126, 0.0, 0.0, 0.0, 0.0, 0.5012279391934354, 0.14361151525658541, 0.0, 0.05781748261134272, 0.17152855777668224, 0.0, 0.498484457540378, 0.0, 0.0, 0.7074889608036871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36413161255211174, 0.10650975776468122, 0.0027919607805886224, 0.1717164070699339, 0.0, 0.0, 0.0, 0.31636490805397033, 0.0, 0.0, 0.0, 0.3781004501122092, 0.1664160983543511, 0.0, 0.10894483484211534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06899783350353156, 0.1313910038295779, 0.5458205926873976, 0.0, 0.2058361256028114, 0.0983057734206431, 0.006586106310131405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13715236217863272, 0.026867165999227966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035515304259612105, 0.0, 0.0, 0.5329776529167246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397719517913955, 0.20668056810136554, 0.1307286941015916, 0.0, 0.19979734260211207, 0.13509882393613562, 0.0, 0.0, 0.0, 0.4428910220796438, 0.0, 0.10971922982381796, 0.20405686697329703, 0.0, 0.0, 0.0, 0.4155385933508652, 0.0, 0.030373091671251427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02870549966274466, 0.0, 2.221236796150802e-5, 0.04518680503118196, 0.8557997812159583, 0.0, 0.0, 0.0, 0.33295230926411423, 0.0, 0.0, 0.1651823382455281, 0.0, 0.0, 0.10987547938954217, 0.038321493889877094, 0.0, 0.0, 0.9167265220224268, 0.0, 0.41223669995910156, 0.0062879102301798264, 0.006460790579658201, 0.0, 0.015093288171720337, 0.004653032070207847, 0.0, 0.0, 0.21192982566516394, 0.0, 0.5265530542756913, 0.004398370159579225, 0.3103332077675556, 0.0, 0.0, 0.21886457786346297, 0.058793164358353744, 0.24052003353974485, 0.5039916994286584, 0.08865805888962155, 0.0, 1.2109591957845456, 0.0, 0.4576423956337198, 0.13738787883657938, 0.3665641879979031, 0.00039223002823340837, 0.0, 0.6257753572135888, 0.0, 1.0620388990418166, 0.04837586177991647, 0.05564954721706949, 0.23699310888410263, 0.0060621596830514254, 1.2406804285104875, 0.0, 0.6055788924273563, 0.1024025590217045, 0.41360202805293217, 0.5476995216716073, 0.17831079467145505, 0.0, 0.0, 0.0, 0.14728996725917032, 0.19581503373322434, 0.10219463649126194, 0.0, 0.0, 1.213270546019433, 0.06327342954871182, 0.0, 0.0, 0.34855390390603164, 0.0, 0.0, 0.2854684709047343, 0.28462687503630496, 0.0, 0.0, 0.0, 0.06675489490570531, 0.4113308129658067, 0.0, 0.049609846106367136, 0.0, 0.0, 0.0, 0.0, 0.2938483162830928, 0.35256998241930354, 0.0, 0.15126367898557985, 0.0, 0.0, 0.1430373863296425, 0.0, 0.11979050068949273, 0.0, 0.0, 0.0, 0.2174719417996252, 0.18492143615091797, 0.5613745989840638, 0.0, 0.1269084936189851, 0.13050728832210684, 0.0, 0.008090983120695843, 0.11645462945856581, 0.45646266655488743, 0.0, 0.0, 0.018120109170533364, 0.0, 0.0, 0.18217259219167142, 0.0, 0.0, 0.23544229686275722, 0.0, 0.072369241454098, 0.0, 0.013298187548207349, 0.0, 0.15536962738337737, 0.0, 0.0, 0.0, 0.5485281455413065, 0.0, 0.0, 0.0, 0.07504798957314487, 0.13800884999205565, 0.023881103672210243, 0.4000634234277266, 0.0, 0.63983454521553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1274757935226854, 0.0, 0.060340389443721644, 0.0, 0.0, 0.0, 0.0, 0.046886662511488715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4105919579209241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17717763704599515, 0.0, 0.0, 0.006078729370399735, 0.0, 0.0, 0.0, 0.4419304781486809, 0.004498905638339938, 0.0, 0.0, 0.06013187036225827, 0.061837053761552255, 0.158000195476362, 0.08245930986204707, 0.055178613203866224, 0.0, 0.3921588247960043, 0.051054375379452996, 0.0, 0.3113852203955569, 0.0, 0.08631714383210826, 0.016249403505819805, 0.0, 0.5064243516388502, 0.0, 0.0799687272151233, 0.0, 0.06016447367008715, 0.0, 0.0, 0.12723000596711698, 0.0, 0.0, 0.0, 0.0, 0.3344116617465516, 0.28448339782348236, 0.03555929040895464, 0.12972821265302345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771825347353467, 0.0, 0.06101920493228206, 0.0, 0.1422424089220273, 0.0, 0.0, 0.0850349690926388, 0.0, 0.6465489235087094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9592391331341867, 0.0, 0.0, 0.0, 0.07533170200640231, 0.3935757364788316, 0.41733426606664215, 0.0, 0.0, 0.0, 0.0, 0.8096836326115127, 0.0, 0.0, 0.15672712010482948, 0.08471008784973191, 0.0, 0.0, 0.021315681001762884, 0.0, 0.0, 0.0, 0.6515686149424397, 0.0, 0.04354065349809789, 0.5887361460115157, 0.0, 0.3314629690186724, 0.08254082170798169, 0.0, 0.5363022284331493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20539826744479112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20437563182844645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08512737043917705, 0.0, 0.0, 0.0, 0.21221590140088104, 0.0, 0.5922163084848736, 0.0, 0.054946173604955253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11912480847073124, 0.10340745987043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22405559305996067, 0.04389088686607588, 0.0, 0.8369237022137216, 0.0, 0.0, 0.303533841030579, 0.8437244477194209, 0.0, 0.0, 0.6770220530788269, 0.0, 0.08868596150524616, 0.0, 0.0, 0.0, 0.005801870585523199, 0.0, 0.3067127385215406, 1.9980597464483445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818471988215991, 0.0, 0.0, 0.0, 0.0, 0.09250846502860006, 0.0, 0.0, 0.0, 0.14804755431292183, 0.0, 0.3797383608658618, 0.39017892030987883, 0.0, 0.035065009177551926, 0.28100508860898343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656255916096575, 0.01029999428072384, 0.026319871200300066, 0.0, 0.0, 0.35174701729018143, 0.019026589888644814, 0.0, 0.0, 0.0, 0.0, 0.10260912587786382, 0.0, 0.0204467738415142, 0.0, 0.023687486390763176, 0.0, 0.0, 0.002174927201126577, 0.0, 0.09114373059640297, 0.0, 0.2642096712527522, 0.3907643461384895, 0.0, 0.0, 0.18051818330232947, 0.0, 0.3874221185422575, 0.6531078672631825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15551832566217896, 0.0, 0.1916820827839075, 0.0, 0.0, 0.08276135601321193, 0.0, 0.10030127909330487, 0.0, 0.0, 0.0, 0.10537887040654752, 0.0, 0.17805025311577488, 0.0, 0.010472659941918684, 0.0, 0.0, 0.007619143135798, 0.0, 0.12561988447587705, 0.0, 0.0, 0.7794014171836517, 0.0, 0.08402510727068294, 0.0, 0.3682135686649267, 0.08647369259665981, 0.09410614716697653, 0.611021014238459, 0.0, 0.0, 0.023955493193970948, 0.0, 0.0, 0.007434430348560844, 0.0, 0.0, 0.0, 0.24285369100807747, 0.0, 0.0, 0.0051185021691807515, 0.0, 0.0015127483220163092, 0.0, 0.0, 0.06096785123225053, 0.014193124550026902, 0.5775319451121608, 0.0, 0.0, 0.0, 0.007997400222196374, 0.6747251647940697, 0.0, 0.0, 0.0, 0.0, 0.7027693457851822, 0.0, 0.0, 0.055434654145900264, 0.0, 0.0, 0.0, 0.02587284155878174, 0.0, 0.42673143134824615, 0.004724246163513554, 0.4406790171730267, 0.0, 1.0342538585019783, 0.5747154140513469, 0.0, 0.9363482803339344, 0.7135280098555865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9563104993907826, 0.0, 0.0, 0.0, 0.8295023845011231, 0.10509888461130146, 0.2471322355632557, 0.3801044173906537, 0.0, 0.0, 0.0, 0.1514367226333477, 0.0, 0.0, 0.0, 0.24534157695942965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052661051195310594, 0.6550399256456869, 0.5803102488724085, 0.0, 0.5319072548222628, 0.46172731619827034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026741428574906606, 0.0, 0.7082513040743756, 0.0, 0.0, 0.4418255985655133, 0.1449878921305842, 0.3039326972841545, 0.0, 0.0, 0.0, 1.198252644211342, 0.44500849169967277, 0.23918686672510267, 0.0, 0.0, 0.19736692078049992, 0.0, 0.0, 0.0, 0.0762301466058952, 0.3507440605568865, 0.4669973871873196, 0.0, 0.06417785026076955, 0.0, 0.0, 0.07892920039677795, 0.20151756987027533, 0.0, 0.5298004507120764, 0.006913800133275409, 0.0, 0.0742780358218034, 0.0, 0.6026732223863505, 0.0, 0.0, 0.5351202277676342, 0.0, 0.0, 0.9548891902757952, 0.02916984862304253, 0.0, 0.4970347785792808, 0.12683003730681902, 0.0180604034141702, 0.0, 0.2650052427173023, 0.0, 0.033791924886614616, 0.0, 0.04181580147667587, 0.0, 0.4621910495164758, 0.0, 0.0, 0.0190541328400638, 0.0, 0.17864673433347314, 0.014160348828667728, 0.8165447001064132, 0.09368415058058097, 0.9079968531646069, 0.08687864486537158, 0.19492858047186096, 0.10063554575175, 0.0, 0.09210666608746948, 0.01874477292287561, 0.03748966025771319, 0.0, 0.5779501492966836, 0.0012862204434733993, 0.220963909203652, 0.3086404911712966, 0.17631145912557372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3032159896791554, 0.0, 0.1846953640258127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07139034913327573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37871083555251084, 0.0, 0.0, 0.0, 0.0, 0.19265602282403793, 0.0, 0.0, 0.606424267788203, 0.011600938808477314, 0.0, 0.63655122023184, 0.8091094673344561, 0.15945386155042648, 0.21681046587583439, 0.5841977471111124, 0.14228431684797266, 0.0, 0.4919831840901785, 0.07005765326837811, 0.0, 0.4452652454663618, 0.0, 0.2225785522561698, 0.0, 0.0, 0.565764962530824, 0.0, 0.0, 0.0, 0.09016013522690633, 0.0, 0.0, 0.054929050345560504, 0.0, 0.0, 0.0397070718161962, 0.0, 0.3253549491861982, 0.39037279561642807, 0.09169366625332782, 0.16748228205826332, 0.0, 0.0, 0.6136975564576865, 0.0, 0.0, 0.3026006369046373, 0.0, 0.649431418360159, 0.08211939816658421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8259750138040276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5145740577075524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45723140022915015, 0.0, 0.0, 0.9202097992461084, 0.168004673879535, 0.0, 0.0, 0.1251531867765232, 0.0, 0.2137981131137785, 0.0, 0.013898368242301713, 0.0, 0.0, 0.7137867360685719, 0.0, 0.0, 0.1000729174155476, 0.0, 0.0, 0.03483089759667312, 0.12636252602014256, 0.0, 0.6417666786106352, 0.47874755782682904, 0.0, 0.0, 0.42719736321019475, 0.0, 0.269711179183823, 0.0, 0.0, 0.0, 0.0, 0.668274429237161, 0.0, 0.0, 0.19736413928693208, 0.0, 0.64140191275638, 0.0, 0.04878252313782071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7804894714968978, 0.1354649020531392, 0.7521947991243342, 0.061565240681645095, 0.7064549771516211, 0.0, 0.0, 0.0, 0.1369213608036062, 0.598180503319145, 0.0, 0.4894142513129519, 0.14663698801711797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14418506746458087, 0.027360830334206502, 0.0, 0.0, 0.11896445459410832, 0.016940356460817766, 0.08867849541915622, 0.0, 0.0, 0.0, 0.0, 0.014527597186767355, 0.0, 0.0, 0.0, 0.0, 0.017872458048705516, 0.09208038488681886, 0.0, 0.01328217046242409, 0.0, 0.0, 0.0, 0.0, 0.07867275819804301, 0.09439445944634833, 0.0, 0.040498210068061674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)

