julia> @finch begin
        CR .= 0
        for i = _
            for j = _
                for k = _
                    CR[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(CR = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            phase_start_2 = max(1, 1 + fld(A_lvl.shape[1] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                for i_7 = phase_start_2:phase_stop_2
                    B_lvl_q = B_lvl_ptr[1]
                    B_lvl_q_stop = B_lvl_ptr[1 + 1]
                    if B_lvl_q < B_lvl_q_stop
                        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                    else
                        B_lvl_i_stop = 0
                    end
                    phase_stop_3 = min(B_lvl.shape[2], B_lvl_i_stop)
                    if phase_stop_3 >= 1
                        if B_lvl_tbl2[B_lvl_q] < 1
                            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        while true
                            B_lvl_i = B_lvl_tbl2[B_lvl_q]
                            B_lvl_q_step = B_lvl_q
                            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                            end
                            if B_lvl_i < phase_stop_3
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_5 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_5 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_5
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_6 = min(B_lvl_i_2, phase_stop_5, A_lvl_i)
                                        if A_lvl_i == phase_stop_6 && B_lvl_i_2 == phase_stop_6
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_7 = min(i_7, A_lvl_i_stop_2)
                                            if phase_stop_7 >= i_7
                                                if A_lvl_tbl1[A_lvl_q] < i_7
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_7
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_9 = min(A_lvl_i_2, phase_stop_7)
                                                        if A_lvl_i_2 == phase_stop_9
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_6
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_6
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_6 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            else
                                phase_stop_14 = min(B_lvl_i, phase_stop_3)
                                if B_lvl_i == phase_stop_14
                                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_14
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_7
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_15 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_15 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_15
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_16 = min(B_lvl_i_2, A_lvl_i, phase_stop_15)
                                            if A_lvl_i == phase_stop_16 && B_lvl_i_2 == phase_stop_16
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_17 = min(i_7, A_lvl_i_stop_4)
                                                if phase_stop_17 >= i_7
                                                    if A_lvl_tbl1[A_lvl_q] < i_7
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_7, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_17
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_19 = min(A_lvl_i_4, phase_stop_17)
                                                            if A_lvl_i_4 == phase_stop_19
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_16
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_16
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_16 + 1
                                        end
                                    end
                                    B_lvl_q = B_lvl_q_step
                                end
                                break
                            end
                        end
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = parallel(_)
            for j = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of Ct[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    for i_4 = 1:A_lvl.shape[1]
        val = Ct_lvl_2_val
        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
        B_lvl_ptr_2 = B_lvl_ptr
        B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
        B_lvl_tbl1_2 = B_lvl_tbl1
        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
        B_lvl_tbl2_2 = B_lvl_tbl2
        B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
        val_2 = B_lvl_val
        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
        A_lvl_ptr_2 = A_lvl_ptr
        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
        A_lvl_tbl1_2 = A_lvl_tbl1
        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
        A_lvl_tbl2_2 = A_lvl_tbl2
        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
        val_3 = A_lvl_val
        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
        Threads.@threads for i_5 = 1:Threads.nthreads()
                B_lvl_q = B_lvl_ptr[1]
                B_lvl_q_stop = B_lvl_ptr[1 + 1]
                if B_lvl_q < B_lvl_q_stop
                    B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
                else
                    B_lvl_i_stop = 0
                end
                phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_5 + -1), Threads.nthreads()))
                phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_5, Threads.nthreads()))
                if phase_stop_2 >= phase_start_2
                    if B_lvl_tbl2[B_lvl_q] < phase_start_2
                        B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    while true
                        B_lvl_i = B_lvl_tbl2[B_lvl_q]
                        B_lvl_q_step = B_lvl_q
                        if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                            B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                        end
                        if B_lvl_i < phase_stop_2
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_4, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_4
                                            if A_lvl_tbl1[A_lvl_q] < i_4
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        else
                            phase_stop_13 = min(B_lvl_i, phase_stop_2)
                            if B_lvl_i == phase_stop_13
                                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_4
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_4, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_4
                                                if A_lvl_tbl1[A_lvl_q] < i_4
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_4, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                                B_lvl_q = B_lvl_q_step
                            end
                            break
                        end
                    end
                end
            end
        Ct_lvl_2_val = val
        B_lvl_ptr = B_lvl_ptr_2
        B_lvl_tbl1 = B_lvl_tbl1_2
        B_lvl_tbl2 = B_lvl_tbl2_2
        B_lvl_val = val_2
        A_lvl_ptr = A_lvl_ptr_2
        A_lvl_tbl1 = A_lvl_tbl1_2
        A_lvl_tbl2 = A_lvl_tbl2_2
        A_lvl_val = val_3
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for i = _
            for j = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        for i_6 = 1:A_lvl.shape[1]
                            Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_6
                            A_lvl_q = A_lvl_ptr[1]
                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                            if A_lvl_q < A_lvl_q_stop
                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                            else
                                A_lvl_i_stop = 0
                            end
                            B_lvl_q_3 = B_lvl_q
                            if B_lvl_q < B_lvl_q_step
                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                            else
                                B_lvl_i_stop_3 = 0
                            end
                            phase_stop_4 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                            if phase_stop_4 >= 1
                                k = 1
                                if A_lvl_tbl2[A_lvl_q] < 1
                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                end
                                if B_lvl_tbl1[B_lvl_q] < 1
                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                end
                                while k <= phase_stop_4
                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                    A_lvl_q_step = A_lvl_q
                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                    phase_stop_5 = min(B_lvl_i_3, phase_stop_4, A_lvl_i)
                                    if A_lvl_i == phase_stop_5 && B_lvl_i_3 == phase_stop_5
                                        B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                        A_lvl_q_2 = A_lvl_q
                                        if A_lvl_q < A_lvl_q_step
                                            A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                        else
                                            A_lvl_i_stop_2 = 0
                                        end
                                        phase_stop_6 = min(i_6, A_lvl_i_stop_2)
                                        if phase_stop_6 >= i_6
                                            if A_lvl_tbl1[A_lvl_q] < i_6
                                                A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_6, A_lvl_q, A_lvl_q_step - 1)
                                            end
                                            while true
                                                A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                if A_lvl_i_2 < phase_stop_6
                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                    A_lvl_q_2 += 1
                                                else
                                                    phase_stop_8 = min(A_lvl_i_2, phase_stop_6)
                                                    if A_lvl_i_2 == phase_stop_8
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    end
                                                    break
                                                end
                                            end
                                        end
                                        A_lvl_q = A_lvl_q_step
                                        B_lvl_q_3 += 1
                                    elseif B_lvl_i_3 == phase_stop_5
                                        B_lvl_q_3 += 1
                                    elseif A_lvl_i == phase_stop_5
                                        A_lvl_q = A_lvl_q_step
                                    end
                                    k = phase_stop_5 + 1
                                end
                            end
                        end
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_13 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_13
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_13
                            for i_8 = 1:A_lvl.shape[1]
                                Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_8
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_3 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_3 = 0
                                end
                                phase_stop_14 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                if phase_stop_14 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_14
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                        phase_stop_15 = min(B_lvl_i_3, A_lvl_i, phase_stop_14)
                                        if A_lvl_i == phase_stop_15 && B_lvl_i_3 == phase_stop_15
                                            B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                            A_lvl_q_4 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_4 = 0
                                            end
                                            phase_stop_16 = min(i_8, A_lvl_i_stop_4)
                                            if phase_stop_16 >= i_8
                                                if A_lvl_tbl1[A_lvl_q] < i_8
                                                    A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_8, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                    if A_lvl_i_4 < phase_stop_16
                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                        A_lvl_q_4 += 1
                                                    else
                                                        phase_stop_18 = min(A_lvl_i_4, phase_stop_16)
                                                        if A_lvl_i_4 == phase_stop_18
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_3 += 1
                                        elseif B_lvl_i_3 == phase_stop_15
                                            B_lvl_q_3 += 1
                                        elseif A_lvl_i == phase_stop_15
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_15 + 1
                                    end
                                end
                            end
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = _
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    B_lvl_q = B_lvl_ptr[1]
    B_lvl_q_stop = B_lvl_ptr[1 + 1]
    if B_lvl_q < B_lvl_q_stop
        B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
    else
        B_lvl_i_stop = 0
    end
    phase_stop = min(B_lvl.shape[2], B_lvl_i_stop)
    if phase_stop >= 1
        if B_lvl_tbl2[B_lvl_q] < 1
            B_lvl_q = Finch.scansearch(B_lvl_tbl2, 1, B_lvl_q, B_lvl_q_stop - 1)
        end
        while true
            B_lvl_i = B_lvl_tbl2[B_lvl_q]
            B_lvl_q_step = B_lvl_q
            if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
            end
            if B_lvl_i < phase_stop
                Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                val = Ct_lvl_2_val
                Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                B_lvl_tbl1_2 = B_lvl_tbl1
                B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                B_lvl_tbl2_2 = B_lvl_tbl2
                val_2 = B_lvl_val
                B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                A_lvl_ptr_2 = A_lvl_ptr
                A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                A_lvl_tbl1_2 = A_lvl_tbl1
                A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                A_lvl_tbl2_2 = A_lvl_tbl2
                A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                val_3 = A_lvl_val
                A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                Threads.@threads for i_9 = 1:Threads.nthreads()
                        phase_start_6 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_9), Threads.nthreads()))
                        phase_stop_7 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_9, Threads.nthreads()))
                        if phase_stop_7 >= phase_start_6
                            for i_12 = phase_start_6:phase_stop_7
                                Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_12
                                A_lvl_q = A_lvl_ptr[1]
                                A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                if A_lvl_q < A_lvl_q_stop
                                    A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                else
                                    A_lvl_i_stop = 0
                                end
                                B_lvl_q_2 = B_lvl_q
                                if B_lvl_q < B_lvl_q_step
                                    B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                else
                                    B_lvl_i_stop_2 = 0
                                end
                                phase_stop_8 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                if phase_stop_8 >= 1
                                    k = 1
                                    if A_lvl_tbl2[A_lvl_q] < 1
                                        A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                    end
                                    if B_lvl_tbl1[B_lvl_q] < 1
                                        B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                    end
                                    while k <= phase_stop_8
                                        A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                        A_lvl_q_step = A_lvl_q
                                        if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                            A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                        phase_stop_9 = min(B_lvl_i_2, phase_stop_8, A_lvl_i)
                                        if A_lvl_i == phase_stop_9 && B_lvl_i_2 == phase_stop_9
                                            B_lvl_2_val = B_lvl_val[B_lvl_q_2]
                                            A_lvl_q_2 = A_lvl_q
                                            if A_lvl_q < A_lvl_q_step
                                                A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                            else
                                                A_lvl_i_stop_2 = 0
                                            end
                                            phase_stop_10 = min(i_12, A_lvl_i_stop_2)
                                            if phase_stop_10 >= i_12
                                                if A_lvl_tbl1[A_lvl_q] < i_12
                                                    A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_12, A_lvl_q, A_lvl_q_step - 1)
                                                end
                                                while true
                                                    A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                    if A_lvl_i_2 < phase_stop_10
                                                        A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                        Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                        A_lvl_q_2 += 1
                                                    else
                                                        phase_stop_12 = min(A_lvl_i_2, phase_stop_10)
                                                        if A_lvl_i_2 == phase_stop_12
                                                            A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                            Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                            A_lvl_q_2 += 1
                                                        end
                                                        break
                                                    end
                                                end
                                            end
                                            A_lvl_q = A_lvl_q_step
                                            B_lvl_q_2 += 1
                                        elseif B_lvl_i_2 == phase_stop_9
                                            B_lvl_q_2 += 1
                                        elseif A_lvl_i == phase_stop_9
                                            A_lvl_q = A_lvl_q_step
                                        end
                                        k = phase_stop_9 + 1
                                    end
                                end
                            end
                        end
                    end
                Ct_lvl_2_val = val
                B_lvl_tbl1 = B_lvl_tbl1_2
                B_lvl_tbl2 = B_lvl_tbl2_2
                B_lvl_val = val_2
                A_lvl_ptr = A_lvl_ptr_2
                A_lvl_tbl1 = A_lvl_tbl1_2
                A_lvl_tbl2 = A_lvl_tbl2_2
                A_lvl_val = val_3
                B_lvl_q = B_lvl_q_step
            else
                phase_stop_18 = min(B_lvl_i, phase_stop)
                if B_lvl_i == phase_stop_18
                    Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_18
                    val_4 = Ct_lvl_2_val
                    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                    B_lvl_tbl1_3 = B_lvl_tbl1
                    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                    B_lvl_tbl2_3 = B_lvl_tbl2
                    val_5 = B_lvl_val
                    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                    A_lvl_ptr_3 = A_lvl_ptr
                    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                    A_lvl_tbl1_3 = A_lvl_tbl1
                    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                    A_lvl_tbl2_3 = A_lvl_tbl2
                    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                    val_6 = A_lvl_val
                    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                    Threads.@threads for i_19 = 1:Threads.nthreads()
                            phase_start_21 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_19), Threads.nthreads()))
                            phase_stop_23 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_19, Threads.nthreads()))
                            if phase_stop_23 >= phase_start_21
                                for i_22 = phase_start_21:phase_stop_23
                                    Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_22
                                    A_lvl_q = A_lvl_ptr[1]
                                    A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                    if A_lvl_q < A_lvl_q_stop
                                        A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                    else
                                        A_lvl_i_stop = 0
                                    end
                                    B_lvl_q_2 = B_lvl_q
                                    if B_lvl_q < B_lvl_q_step
                                        B_lvl_i_stop_2 = B_lvl_tbl1[B_lvl_q_step - 1]
                                    else
                                        B_lvl_i_stop_2 = 0
                                    end
                                    phase_stop_24 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_2)
                                    if phase_stop_24 >= 1
                                        k = 1
                                        if A_lvl_tbl2[A_lvl_q] < 1
                                            A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                        end
                                        if B_lvl_tbl1[B_lvl_q] < 1
                                            B_lvl_q_2 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                        end
                                        while k <= phase_stop_24
                                            A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                            A_lvl_q_step = A_lvl_q
                                            if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            B_lvl_i_2 = B_lvl_tbl1[B_lvl_q_2]
                                            phase_stop_25 = min(B_lvl_i_2, A_lvl_i, phase_stop_24)
                                            if A_lvl_i == phase_stop_25 && B_lvl_i_2 == phase_stop_25
                                                B_lvl_2_val_3 = B_lvl_val[B_lvl_q_2]
                                                A_lvl_q_4 = A_lvl_q
                                                if A_lvl_q < A_lvl_q_step
                                                    A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                else
                                                    A_lvl_i_stop_4 = 0
                                                end
                                                phase_stop_26 = min(i_22, A_lvl_i_stop_4)
                                                if phase_stop_26 >= i_22
                                                    if A_lvl_tbl1[A_lvl_q] < i_22
                                                        A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_22, A_lvl_q, A_lvl_q_step - 1)
                                                    end
                                                    while true
                                                        A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                        if A_lvl_i_4 < phase_stop_26
                                                            A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                            Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                            A_lvl_q_4 += 1
                                                        else
                                                            phase_stop_28 = min(A_lvl_i_4, phase_stop_26)
                                                            if A_lvl_i_4 == phase_stop_28
                                                                A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                A_lvl_q_4 += 1
                                                            end
                                                            break
                                                        end
                                                    end
                                                end
                                                A_lvl_q = A_lvl_q_step
                                                B_lvl_q_2 += 1
                                            elseif B_lvl_i_2 == phase_stop_25
                                                B_lvl_q_2 += 1
                                            elseif A_lvl_i == phase_stop_25
                                                A_lvl_q = A_lvl_q_step
                                            end
                                            k = phase_stop_25 + 1
                                        end
                                    end
                                end
                            end
                        end
                    Ct_lvl_2_val = val_4
                    B_lvl_tbl1 = B_lvl_tbl1_3
                    B_lvl_tbl2 = B_lvl_tbl2_3
                    B_lvl_val = val_5
                    A_lvl_ptr = A_lvl_ptr_3
                    A_lvl_tbl1 = A_lvl_tbl1_3
                    A_lvl_tbl2 = A_lvl_tbl2_3
                    A_lvl_val = val_6
                    B_lvl_q = B_lvl_q_step
                end
                break
            end
        end
    end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(Ct_lvl_2_val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = _
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)
julia> @finch_code begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
quote
    Ct_lvl = (ex.bodies[1]).tns.bind.lvl
    Ct_lvl_2 = Ct_lvl.lvl
    Ct_lvl_3 = Ct_lvl_2.lvl
    Ct_lvl_2_val = Ct_lvl_2.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.ptr
    A_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[1]
    A_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[1]).tns.bind.lvl.tbl[2]
    A_lvl_val = A_lvl.lvl.val
    B_lvl = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl
    B_lvl_ptr = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.ptr
    B_lvl_tbl1 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[1]
    B_lvl_tbl2 = ((ex.bodies[2]).body.body.body.rhs.args[2]).tns.bind.lvl.tbl[2]
    B_lvl_val = B_lvl.lvl.val
    B_lvl.shape[1] == A_lvl.shape[2] || throw(DimensionMismatch("mismatched dimension limits ($(B_lvl.shape[1]) != $(A_lvl.shape[2]))"))
    @warn "Performance Warning: non-concordant traversal of A[i, k] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)"
    pos_stop = A_lvl.shape[1] * B_lvl.shape[2]
    Finch.resize_if_smaller!(Ct_lvl_2_val, pos_stop)
    Finch.fill_range!(Ct_lvl_2_val, 0.0, 1, pos_stop)
    val = Ct_lvl_2_val
    Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
    B_lvl_ptr = moveto(B_lvl_ptr, CPU(Threads.nthreads()))
    B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
    B_lvl_tbl2 = moveto(B_lvl_tbl2, CPU(Threads.nthreads()))
    B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
    A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
    A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            B_lvl_q = B_lvl_ptr[1]
            B_lvl_q_stop = B_lvl_ptr[1 + 1]
            if B_lvl_q < B_lvl_q_stop
                B_lvl_i_stop = B_lvl_tbl2[B_lvl_q_stop - 1]
            else
                B_lvl_i_stop = 0
            end
            phase_start_2 = max(1, 1 + fld(B_lvl.shape[2] * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(B_lvl.shape[2], B_lvl_i_stop, fld(B_lvl.shape[2] * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                if B_lvl_tbl2[B_lvl_q] < phase_start_2
                    B_lvl_q = Finch.scansearch(B_lvl_tbl2, phase_start_2, B_lvl_q, B_lvl_q_stop - 1)
                end
                while true
                    B_lvl_i = B_lvl_tbl2[B_lvl_q]
                    B_lvl_q_step = B_lvl_q
                    if B_lvl_tbl2[B_lvl_q] == B_lvl_i
                        B_lvl_q_step = Finch.scansearch(B_lvl_tbl2, B_lvl_i + 1, B_lvl_q, B_lvl_q_stop - 1)
                    end
                    if B_lvl_i < phase_stop_2
                        Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + B_lvl_i
                        val_4 = Ct_lvl_2_val
                        Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                        A_lvl_ptr_3 = A_lvl_ptr
                        A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                        A_lvl_tbl1_3 = A_lvl_tbl1
                        A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                        A_lvl_tbl2_3 = A_lvl_tbl2
                        A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                        val_5 = A_lvl_val
                        A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                        B_lvl_ptr_3 = B_lvl_ptr
                        B_lvl_tbl1_3 = B_lvl_tbl1
                        B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                        B_lvl_tbl2_3 = B_lvl_tbl2
                        val_6 = B_lvl_val
                        B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                        Threads.@threads for i_10 = 1:Threads.nthreads()
                                phase_start_7 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_10), Threads.nthreads()))
                                phase_stop_8 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_10, Threads.nthreads()))
                                if phase_stop_8 >= phase_start_7
                                    for i_13 = phase_start_7:phase_stop_8
                                        Ct_lvl_2_q = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_13
                                        A_lvl_q = A_lvl_ptr[1]
                                        A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                        if A_lvl_q < A_lvl_q_stop
                                            A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                        else
                                            A_lvl_i_stop = 0
                                        end
                                        B_lvl_q_3 = B_lvl_q
                                        if B_lvl_q < B_lvl_q_step
                                            B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                        else
                                            B_lvl_i_stop_3 = 0
                                        end
                                        phase_stop_9 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                        if phase_stop_9 >= 1
                                            k = 1
                                            if A_lvl_tbl2[A_lvl_q] < 1
                                                A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                            end
                                            if B_lvl_tbl1[B_lvl_q] < 1
                                                B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                            end
                                            while k <= phase_stop_9
                                                A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                A_lvl_q_step = A_lvl_q
                                                if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                    A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                phase_stop_10 = min(B_lvl_i_3, phase_stop_9, A_lvl_i)
                                                if A_lvl_i == phase_stop_10 && B_lvl_i_3 == phase_stop_10
                                                    B_lvl_2_val = B_lvl_val[B_lvl_q_3]
                                                    A_lvl_q_2 = A_lvl_q
                                                    if A_lvl_q < A_lvl_q_step
                                                        A_lvl_i_stop_2 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                    else
                                                        A_lvl_i_stop_2 = 0
                                                    end
                                                    phase_stop_11 = min(i_13, A_lvl_i_stop_2)
                                                    if phase_stop_11 >= i_13
                                                        if A_lvl_tbl1[A_lvl_q] < i_13
                                                            A_lvl_q_2 = Finch.scansearch(A_lvl_tbl1, i_13, A_lvl_q, A_lvl_q_step - 1)
                                                        end
                                                        while true
                                                            A_lvl_i_2 = A_lvl_tbl1[A_lvl_q_2]
                                                            if A_lvl_i_2 < phase_stop_11
                                                                A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                A_lvl_q_2 += 1
                                                            else
                                                                phase_stop_13 = min(A_lvl_i_2, phase_stop_11)
                                                                if A_lvl_i_2 == phase_stop_13
                                                                    A_lvl_2_val = A_lvl_val[A_lvl_q_2]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q] = Ct_lvl_2_val[Ct_lvl_2_q] + B_lvl_2_val * A_lvl_2_val
                                                                    A_lvl_q_2 += 1
                                                                end
                                                                break
                                                            end
                                                        end
                                                    end
                                                    A_lvl_q = A_lvl_q_step
                                                    B_lvl_q_3 += 1
                                                elseif B_lvl_i_3 == phase_stop_10
                                                    B_lvl_q_3 += 1
                                                elseif A_lvl_i == phase_stop_10
                                                    A_lvl_q = A_lvl_q_step
                                                end
                                                k = phase_stop_10 + 1
                                            end
                                        end
                                    end
                                end
                            end
                        Ct_lvl_2_val = val_4
                        A_lvl_ptr = A_lvl_ptr_3
                        A_lvl_tbl1 = A_lvl_tbl1_3
                        A_lvl_tbl2 = A_lvl_tbl2_3
                        A_lvl_val = val_5
                        B_lvl_ptr = B_lvl_ptr_3
                        B_lvl_tbl1 = B_lvl_tbl1_3
                        B_lvl_tbl2 = B_lvl_tbl2_3
                        B_lvl_val = val_6
                        B_lvl_q = B_lvl_q_step
                    else
                        phase_stop_19 = min(B_lvl_i, phase_stop_2)
                        if B_lvl_i == phase_stop_19
                            Ct_lvl_q = (1 - 1) * B_lvl.shape[2] + phase_stop_19
                            val_7 = Ct_lvl_2_val
                            Ct_lvl_2_val = moveto(Ct_lvl_2_val, CPU(Threads.nthreads()))
                            A_lvl_ptr_4 = A_lvl_ptr
                            A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
                            A_lvl_tbl1_4 = A_lvl_tbl1
                            A_lvl_tbl1 = moveto(A_lvl_tbl1, CPU(Threads.nthreads()))
                            A_lvl_tbl2_4 = A_lvl_tbl2
                            A_lvl_tbl2 = moveto(A_lvl_tbl2, CPU(Threads.nthreads()))
                            val_8 = A_lvl_val
                            A_lvl_val = moveto(A_lvl_val, CPU(Threads.nthreads()))
                            B_lvl_ptr_4 = B_lvl_ptr
                            B_lvl_tbl1_4 = B_lvl_tbl1
                            B_lvl_tbl1 = moveto(B_lvl_tbl1, CPU(Threads.nthreads()))
                            B_lvl_tbl2_4 = B_lvl_tbl2
                            val_9 = B_lvl_val
                            B_lvl_val = moveto(B_lvl_val, CPU(Threads.nthreads()))
                            Threads.@threads for i_20 = 1:Threads.nthreads()
                                    phase_start_22 = max(1, 1 + fld(A_lvl.shape[1] * (-1 + i_20), Threads.nthreads()))
                                    phase_stop_24 = min(A_lvl.shape[1], fld(A_lvl.shape[1] * i_20, Threads.nthreads()))
                                    if phase_stop_24 >= phase_start_22
                                        for i_23 = phase_start_22:phase_stop_24
                                            Ct_lvl_2_q_2 = (Ct_lvl_q - 1) * A_lvl.shape[1] + i_23
                                            A_lvl_q = A_lvl_ptr[1]
                                            A_lvl_q_stop = A_lvl_ptr[1 + 1]
                                            if A_lvl_q < A_lvl_q_stop
                                                A_lvl_i_stop = A_lvl_tbl2[A_lvl_q_stop - 1]
                                            else
                                                A_lvl_i_stop = 0
                                            end
                                            B_lvl_q_3 = B_lvl_q
                                            if B_lvl_q < B_lvl_q_step
                                                B_lvl_i_stop_3 = B_lvl_tbl1[B_lvl_q_step - 1]
                                            else
                                                B_lvl_i_stop_3 = 0
                                            end
                                            phase_stop_25 = min(B_lvl.shape[1], A_lvl_i_stop, B_lvl_i_stop_3)
                                            if phase_stop_25 >= 1
                                                k = 1
                                                if A_lvl_tbl2[A_lvl_q] < 1
                                                    A_lvl_q = Finch.scansearch(A_lvl_tbl2, 1, A_lvl_q, A_lvl_q_stop - 1)
                                                end
                                                if B_lvl_tbl1[B_lvl_q] < 1
                                                    B_lvl_q_3 = Finch.scansearch(B_lvl_tbl1, 1, B_lvl_q, B_lvl_q_step - 1)
                                                end
                                                while k <= phase_stop_25
                                                    A_lvl_i = A_lvl_tbl2[A_lvl_q]
                                                    A_lvl_q_step = A_lvl_q
                                                    if A_lvl_tbl2[A_lvl_q] == A_lvl_i
                                                        A_lvl_q_step = Finch.scansearch(A_lvl_tbl2, A_lvl_i + 1, A_lvl_q, A_lvl_q_stop - 1)
                                                    end
                                                    B_lvl_i_3 = B_lvl_tbl1[B_lvl_q_3]
                                                    phase_stop_26 = min(B_lvl_i_3, A_lvl_i, phase_stop_25)
                                                    if A_lvl_i == phase_stop_26 && B_lvl_i_3 == phase_stop_26
                                                        B_lvl_2_val_3 = B_lvl_val[B_lvl_q_3]
                                                        A_lvl_q_4 = A_lvl_q
                                                        if A_lvl_q < A_lvl_q_step
                                                            A_lvl_i_stop_4 = A_lvl_tbl1[A_lvl_q_step - 1]
                                                        else
                                                            A_lvl_i_stop_4 = 0
                                                        end
                                                        phase_stop_27 = min(i_23, A_lvl_i_stop_4)
                                                        if phase_stop_27 >= i_23
                                                            if A_lvl_tbl1[A_lvl_q] < i_23
                                                                A_lvl_q_4 = Finch.scansearch(A_lvl_tbl1, i_23, A_lvl_q, A_lvl_q_step - 1)
                                                            end
                                                            while true
                                                                A_lvl_i_4 = A_lvl_tbl1[A_lvl_q_4]
                                                                if A_lvl_i_4 < phase_stop_27
                                                                    A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                    Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                    A_lvl_q_4 += 1
                                                                else
                                                                    phase_stop_29 = min(A_lvl_i_4, phase_stop_27)
                                                                    if A_lvl_i_4 == phase_stop_29
                                                                        A_lvl_2_val_2 = A_lvl_val[A_lvl_q_4]
                                                                        Ct_lvl_2_val[Ct_lvl_2_q_2] = Ct_lvl_2_val[Ct_lvl_2_q_2] + B_lvl_2_val_3 * A_lvl_2_val_2
                                                                        A_lvl_q_4 += 1
                                                                    end
                                                                    break
                                                                end
                                                            end
                                                        end
                                                        A_lvl_q = A_lvl_q_step
                                                        B_lvl_q_3 += 1
                                                    elseif B_lvl_i_3 == phase_stop_26
                                                        B_lvl_q_3 += 1
                                                    elseif A_lvl_i == phase_stop_26
                                                        A_lvl_q = A_lvl_q_step
                                                    end
                                                    k = phase_stop_26 + 1
                                                end
                                            end
                                        end
                                    end
                                end
                            Ct_lvl_2_val = val_7
                            A_lvl_ptr = A_lvl_ptr_4
                            A_lvl_tbl1 = A_lvl_tbl1_4
                            A_lvl_tbl2 = A_lvl_tbl2_4
                            A_lvl_val = val_8
                            B_lvl_ptr = B_lvl_ptr_4
                            B_lvl_tbl1 = B_lvl_tbl1_4
                            B_lvl_tbl2 = B_lvl_tbl2_4
                            B_lvl_val = val_9
                            B_lvl_q = B_lvl_q_step
                        end
                        break
                    end
                end
            end
        end
    qos = 1 * B_lvl.shape[2]
    qos_2 = qos * A_lvl.shape[1]
    resize!(val, qos_2)
    (Ct = Tensor((DenseLevel){Int64}((DenseLevel){Int64}(Ct_lvl_3, A_lvl.shape[1]), B_lvl.shape[2])),)
end
julia> @finch begin
        Ct .= 0
        for j = parallel(_)
            for i = parallel(_)
                for k = _
                    Ct[i, j] += A[i, k] * B[k, j]
                end
            end
        end
    end
(Ct = Tensor(Dense{Int64}(Dense{Int64}(Element{0.0, Float64, Int64}([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25238968158185693, 0.0, 0.0, 0.48865059160643304, 0.11871952163266221, 0.13783085437527975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1100520583840872, 0.0, 0.6593611321473758, 0.05928345080192752, 0.009174411759749758, 0.0, 0.0, 0.19127876171690858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07691735887883953, 0.0, 0.05392395392410878, 0.02141387988861775, 0.34710885925020263, 0.0, 0.0, 0.0, 0.0, 0.004888456103411815, 0.23938597192062988, 0.14380896793554465, 0.0, 0.0, 0.11091906743258541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42492930113736893, 0.0, 0.0, 0.0, 0.3917786049138451, 0.0, 0.027947398300345625, 0.0, 0.0, 0.0, 0.027990755993474236, 0.23996972136870412, 0.0, 0.0, 0.0, 0.16076348282437408, 0.0, 0.0, 0.0, 0.0, 0.2346717239666177, 0.0, 0.1645197835042719, 0.0, 0.15581124610211206, 0.0, 0.0, 0.0, 0.0, 0.16923528472284902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802881298690809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008989792695458017, 0.0, 0.0, 0.0, 0.0, 0.06720357557125424, 0.0, 0.0, 0.0, 0.3718711629986387, 0.0, 0.0, 0.3609126159300422, 0.1163460342216259, 0.26803502779771143, 0.5785179690130179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20913099459980355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3230898388302748, 0.31857597482541405, 0.458635468333174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7731954314831251, 0.7216673432976093, 0.0, 0.7303507448180484, 0.14951424728459475, 0.7849205313632122, 0.0, 0.61487751501265, 0.0, 0.0, 0.25756111513158075, 0.0, 0.4611561614453371, 0.11767850077853764, 0.8141145056659213, 0.17774815965387922, 0.0, 0.0, 0.6559733835287642, 0.36761704346577023, 0.0, 0.0, 0.0, 0.7451998098255509, 0.033169973232688346, 0.411513621864204, 0.20930644094410764, 0.0, 0.0, 0.0, 0.10412334822136202, 0.6428221612529075, 0.2944149731643712, 0.0, 0.01883057275583864, 0.0, 0.05108593913912473, 0.0, 0.0, 0.521025535425184, 0.0008200368898190739, 0.0, 1.1919622969351262, 0.6934669965376988, 0.46942192138741023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37125241315091917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29594902098744047, 0.0, 0.0, 0.0, 0.5073161019921272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36145064005412786, 0.0, 0.054781056420259586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6055780045451759, 0.09162757378665623, 0.04766798091106047, 0.0, 0.46059427954757914, 0.1119031338013209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37567607243684537, 0.6215033212682567, 0.6577405362916645, 0.03204652922702584, 0.0, 0.0650525320202852, 0.18029632002719695, 0.0, 0.0, 0.0, 0.0, 0.008472932483726157, 0.0, 0.0, 0.0, 0.0, 0.13094335555018422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16141065848651698, 0.0, 0.051110856273358346, 0.0, 0.020946973304893955, 0.06226614898669832, 0.0, 0.2444646619775439, 0.0, 0.0, 0.0, 0.0, 0.04963632606956389, 0.0, 0.0, 0.0, 0.08508663882314382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1263166966867768, 0.0, 0.15643691198571966, 0.0, 0.0, 0.0, 0.15262026274680354, 0.0, 0.526388198493186, 0.0, 0.0, 0.033474977962917256, 0.060622203675208805, 0.0, 0.43377644245905544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151002104915899, 0.0, 0.09477312339277622, 0.0, 0.0, 0.0, 0.152252080697694, 0.0, 0.0, 0.0204339991404229, 0.1698000966652489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22850913265749315, 0.0, 0.7903794435818682, 0.5335588868613267, 0.0, 0.0, 0.33064520351324683, 0.11423967014312472, 0.532326845734251, 0.0, 0.0, 0.0, 0.0, 0.5700696949494688, 0.5896247750753707, 0.0, 0.4280369290594203, 0.0, 0.27339018574089047, 0.25517063473696217, 0.0, 0.4053021670425236, 0.0, 0.7145118270418906, 0.18406779329511921, 0.5332101577384002, 0.15679597786898153, 0.0, 0.02405447430944597, 0.5068714011553328, 0.2632866105026604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026822919064352108, 0.0, 0.09441824561660622, 0.15069396874531527, 0.24064671368655893, 0.0, 0.06394357060327457, 0.3982245622181067, 0.22117139549869444, 0.14930545644387866, 0.0, 0.2667835225346214, 0.4473684178329899, 0.0, 0.14896069513005675, 0.0, 0.41433289250349636, 0.0, 0.5041716274275465, 0.26176138019545275, 0.5757006867537102, 0.08966813962959974, 0.11977731163657437, 0.0, 0.0, 0.29331748913539113, 0.14887247084155056, 0.1452951955564375, 0.0, 0.0, 0.0, 0.0, 0.34161907033931543, 0.05898137093682045, 0.05240866036729835, 0.0, 0.0, 0.0, 0.5188204085313443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773724259871397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22601349058504813, 0.0, 0.3467947164134737, 1.502272260353748, 0.19536436403308852, 0.0, 0.0, 0.0, 0.0, 0.4899706257461605, 0.20445136303854802, 0.7748906467295266, 0.0, 0.0, 0.15253741518885644, 0.0, 0.12918615799515507, 0.0, 0.0, 0.649394095142608, 1.40604728101928, 0.0, 0.5734783753787226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8762605287663663, 0.8124102702299425, 0.0, 0.0, 0.6752965428315182, 0.25420065076928294, 0.2878352998155691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8742900027056961, 0.0, 0.007209075676415797, 0.028458058565007462, 0.0, 0.0, 0.002645728789765276, 0.0, 0.0, 0.0, 0.669321167131686, 0.0, 0.0, 0.3215833521867582, 0.002002885293525303, 0.5455785228014223, 0.5839672123490091, 0.1695566125503257, 0.0, 0.0, 0.0, 0.0, 0.3711983399532414, 0.0, 0.0, 0.037869811310371364, 0.0, 0.0, 0.0, 0.3906765181627519, 0.0, 0.0, 0.0, 0.004333175863679718, 0.0, 0.0, 0.0, 0.0029029347517778824, 0.43381543679330525, 0.0, 0.0, 0.0, 0.0, 0.3545426084781949, 0.0, 0.3770558352493434, 0.6375411486503958, 0.0, 0.0, 0.0, 0.23985359098491452, 0.021961946298743228, 0.0, 0.3910697032182053, 0.0, 0.6932074965542865, 0.0, 0.0, 0.10364106821683754, 0.0, 0.798416207733151, 0.5329842919228587, 0.0, 0.4844692491628223, 0.0, 0.0, 0.0, 0.0, 0.09106971306440546, 0.0, 0.0, 0.0996076819499136, 0.0, 0.0, 0.1638248686693664, 0.0, 0.3325546563665125, 0.0, 0.0, 0.0, 0.06881525170797138, 0.0, 0.44073566130025815, 0.0, 0.4019788844385439, 0.0, 0.0, 0.6714215423158676, 0.3399125937167764, 0.3046141011370791, 0.0, 0.0, 0.0473355681300066, 0.3630070132608522, 0.0, 0.0800754636262803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2369140918241696, 0.0, 0.0, 0.35909981102365546, 0.2433693452274136, 0.6477566576645207, 0.0, 0.0, 0.0, 0.0, 0.4005702988980329, 0.6327139875815745, 0.45739813367595, 0.2306117264369203, 0.1673891610155256, 0.0, 0.3233168523165315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211122573483531, 0.0, 0.06803593591564691, 0.5741938845793657, 0.0476975123297982, 0.5504819156825551, 0.044516401141561746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13524675835101255, 0.0, 0.22945132617429284, 0.0, 0.0, 0.0, 0.0, 0.1577714195074665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2785368262709604, 0.12576967984327264, 0.0, 0.0, 0.0, 0.21559450852042064, 0.04903058086742513, 0.0, 0.1695895598298771, 0.11448427397866526, 0.0, 0.0, 0.023071609626772224, 0.0, 0.11421991827694536, 0.0, 0.0, 0.0, 0.007379588146467978, 0.07866376283476462, 0.3892472589606234, 0.0, 0.09184271552047321, 0.0, 0.25448001970252454, 0.2286582495545744, 0.02328034708296836, 0.0, 0.0, 0.0, 0.0, 0.3270923296219218, 0.0, 0.0, 0.0, 0.02043338740984974, 0.0, 0.0, 0.37277616481672965, 0.0, 0.0, 0.0, 0.0044846057268865735, 0.0, 0.3249615768942753, 0.0, 0.0, 0.19094547447052443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08406342406417443, 0.0, 0.033182079075965945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6500195484438399, 0.0, 0.0, 0.0, 0.0, 0.5537781763556555, 0.02656015063015655, 1.1909226087779956, 0.06852425737111054, 0.0, 1.3426353595976268, 0.6057701268300226, 0.9302934294779756, 0.0, 0.02223254227484718, 0.9934644128441693, 0.0, 0.06172390220433867, 0.20273446118005728, 0.5149938580802573, 0.1300590771577626, 0.2385875538652477, 0.0, 0.595480643743492, 0.0, 0.0, 0.0, 0.24275727828178406, 0.0, 0.7073132892445582, 0.0, 0.5182899096571696, 0.0, 0.363354145475898, 1.046444738015761, 0.8990939341913878, 0.5284345996323894, 0.0009271750893556132, 0.0, 0.0786791826827641, 0.5567513178048157, 0.0, 0.11672601563414542, 0.0, 0.0, 0.0, 0.0, 0.513610216882899, 0.0, 0.3599562947175533, 0.012305112294495107, 0.0, 0.3547644724719033, 0.0, 0.31743838097476296, 0.0, 0.0, 0.0744235447925737, 0.0, 0.0, 0.3186229810095584, 0.0, 0.7632822460090717, 0.3112891249755775, 0.0, 1.2592130951288079, 0.4142666686935799, 0.0, 0.0, 0.0834856922205997, 0.0, 0.5673263343800874, 0.0, 0.0, 0.0, 0.011109757680217765, 0.7473278912032746, 0.4577974378546139, 0.07323000489837116, 0.33380163101303967, 0.0, 0.014128663560806082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19621458519667637, 0.0, 0.0, 0.0, 0.0, 0.4083399062549612, 0.0, 0.3744505994071715, 0.0, 0.5655910339236376, 0.0, 0.0, 0.08962016161963385, 0.0, 0.0, 0.0, 0.0, 0.3660241210222327, 0.0, 0.42450374338695224, 0.6660088440351456, 0.0, 0.0, 0.28456417514777416, 0.0, 0.6631091941560893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002609340728317194, 0.0, 0.0, 0.0, 0.0, 0.1290910408202515, 0.0, 0.12880600190077574, 0.0, 0.21852433519062017, 0.14617196989407044, 0.04712090478664361, 0.17786735669510226, 0.013608617966411374, 0.0, 0.1599219758144718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13118766387513575, 0.18575036424480185, 0.0, 0.0, 0.0, 0.0, 0.24739057674609932, 0.08098740885007556, 0.0, 0.0, 0.11169555771003165, 0.0061692969950391426, 0.0, 0.0, 0.0, 0.1300402212804686, 0.0, 0.22061823582759926, 0.32468517510166695, 0.17899843511210062, 0.0, 0.0, 0.0, 0.0, 0.3555268023407697, 0.0, 0.0, 0.0, 0.5637648459713849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41259886956253183, 0.0, 0.0, 0.0, 0.0, 1.0217866044035127, 0.0, 0.0, 0.0, 0.09699076097844603, 0.49177999120325233, 0.617482417183965, 0.9254348782417843, 0.19189797684210885, 0.37564958516196006, 0.0, 0.6028533281724416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4525887449543689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3536752652948492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5159325071456758, 0.45703260113959776, 0.11783337867793497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014395933646557283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5291071006274988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4362705134404812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06167194341482688, 0.0, 0.26507468559563424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18765355736657707, 0.0, 1.0014115383719757, 0.10542483708166006, 0.22040848700903187, 0.0, 0.3600323742449293, 0.06543742592421764, 0.0, 0.06637441639531827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3967141864154841, 0.0, 0.18259679072826512, 0.0, 0.2818810986099949, 0.0, 0.0, 0.0, 0.04462260901941838, 0.650460148621926, 0.9472330785275007, 0.0, 0.0, 0.0, 0.0, 0.20815281221075516, 0.19618764447572262, 0.06473525648539784, 0.0, 0.0, 0.0, 0.1542243249790465, 0.13224172712193835, 0.0, 0.007908832517684252, 0.0, 0.051353982240120374, 0.0032977751233809844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27800255996089945, 0.0, 0.0, 0.1281258773488851, 0.0, 0.0, 0.0, 0.31683019969084447, 0.0, 0.0, 0.0, 0.19099043815219882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2169883137756601, 0.0, 0.7505306274250138, 0.5066582758142599, 0.0, 0.07143979002259558, 0.10210504506442938, 0.15444313156667316, 0.5054883509033501, 0.0, 0.0, 0.0, 0.0028518817212982773, 0.3481320627001662, 0.559897472000501, 0.0, 0.40645645270348807, 0.0, 0.36960222637651485, 0.34497081323202616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0330129037169125, 0.05220506486278423, 0.053654185080025577, 0.0, 0.0, 0.1851124085000456, 0.04497376440934621, 0.35304695602824443, 0.0, 0.0, 0.343295765136816, 0.2793332554556384, 0.0, 0.0, 0.040358875497600165, 0.24978160129073035, 0.0, 0.0, 0.0, 0.0, 0.07246092173943684, 0.0, 0.16628600115413392, 0.0, 0.0, 0.0, 0.06634041958053304, 0.0, 0.0, 0.0, 0.008112084482454424, 0.0, 0.0, 0.3510991071496956, 0.30792356595023396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24591462609017128, 0.0, 0.0, 0.0, 0.0, 0.1723485353456609, 0.17746213232343597, 0.26032482377035826, 0.0, 0.0, 0.09642188463361992, 0.0, 0.0, 0.9312549994812083, 0.0, 0.4355669936335271, 0.22986161845318145, 0.0, 1.1016016643957898, 0.5367168823744637, 0.0, 0.0, 0.1081626494181155, 0.0, 0.5354775491181646, 0.0, 0.0, 0.7066771289166013, 0.005913227901483509, 0.36878575613264597, 0.5931146099182986, 0.0, 0.43177137005853594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2792172801438884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771394461865235, 0.0, 0.3810480475576988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04963057208911237, 0.0, 0.0, 0.0, 0.014028126739435154, 0.6487755206193258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019308069898724092, 0.0, 0.0, 0.15473333790095384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20078144855224883, 0.04664059814698181, 0.0, 0.0, 0.02360446678134394, 0.0, 0.0, 0.06383755139363034, 0.0, 0.1295864000345023, 0.0, 0.0, 0.0972547510814237, 0.0, 0.07205581060374358, 0.016878310254842765, 0.0, 0.0, 0.0, 0.0, 0.2206348639926782, 0.0, 0.0, 0.2053453449704589, 0.18009351088331146, 0.17243879836126652, 0.16094695393647487, 0.0, 0.0, 0.0026102124382687284, 0.009478472183394092, 0.22228584913081856, 0.0, 0.0, 0.22567472183496304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002853715730108796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005790797752150057, 0.4809080576930432, 0.0, 0.0, 0.0, 0.32217587215618376, 0.0018177803358381927, 0.0, 0.0, 0.0, 0.0003287432209283418, 0.0, 0.0008918558343658391, 0.0, 0.0, 0.009096038390466929, 0.0, 0.0, 0.0, 0.00873033402576318, 0.007007183394127084, 0.45496728899530875, 0.0, 0.1316351307673038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09338135584056179, 0.18382194877540864, 0.0, 0.563495172825665, 0.0, 0.0, 0.0, 0.05639497562938005, 0.14653622131196892, 0.0, 0.0, 0.0, 0.251192534270281, 0.1344408525103349, 0.0, 0.4650111134116464, 0.31391354376028213, 0.0, 0.0, 0.06326188293375198, 0.0, 0.31318868581904563, 0.0, 0.0763329064988246, 0.0, 0.0, 0.2156944329452718, 0.3468992967609863, 0.0, 0.2518308523576955, 0.0, 0.17896869808051252, 0.05403813425807818, 0.027124296544448725, 0.0, 0.0, 0.0, 0.0, 0.11640144853391314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09109340489796702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194057971602891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6552661573805515, 0.0, 0.0, 0.0, 0.21450271688804268, 0.0, 0.0, 0.902854749674862, 0.06907734840039648, 0.0, 0.811763991573728, 0.24446155688431725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551218990786032, 0.0, 0.0, 0.6659086165622266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4110921087644639, 0.0, 0.0, 0.07931423881912922, 0.0, 0.0, 0.37316154887557274, 0.11430607897800385, 0.4150800042560803, 0.0, 0.10099097676635159, 0.6592915699634367, 0.0, 0.25936644093477396, 0.07666208914620723, 0.0, 0.0, 0.7807360976520861, 0.0, 0.0, 0.04275453625658718, 0.1985413718724771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13633482744457018, 0.0, 0.2252743029271589, 0.0, 0.0, 0.0, 0.5464410650922171, 0.11366230227156136, 0.6018718955402885, 0.0, 0.014396279790867243, 0.0, 0.03905603312028952, 0.8092451213661034, 0.0, 0.39833251401456404, 0.0, 0.12251229365728535, 0.27200847035734843, 0.25388100105648176, 0.30685765140009125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07517201195249319, 0.0, 0.0, 0.0, 0.0, 0.3595498458067731, 0.0, 0.0, 0.0, 0.05519776563775433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158680513977092, 0.0, 0.45513938379424074, 0.3072494672729318, 0.0, 0.0, 0.061918895238623206, 0.0, 0.306539997354477, 0.0, 0.0, 0.0, 0.0, 0.21111545179707192, 1.113727824196147, 0.0, 0.24648473048642042, 0.0, 0.0, 0.0, 0.6244696783059631, 0.0, 0.0, 0.010619491746539882, 0.0, 0.0, 0.057745206745770994, 0.0, 0.008858840711593166, 0.0075334185627281185, 0.1972006876834336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15720126897663422, 0.2881788570254271, 0.05549794388099826, 0.0, 0.43880673821983995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006158057243750719, 0.0, 0.0, 0.05862006643173159, 0.15125593941090254, 0.03302320207312045, 0.0, 0.0, 0.19199421271725345, 0.004359455697024407, 0.02909842903488052, 0.4051738652139157, 0.0, 0.0, 0.0, 0.0, 0.661857462083124, 0.27266071825745297, 0.09855620143563353, 0.03009452021788303, 0.0, 0.0, 0.36386547477639486, 0.0, 0.3154569959145931, 0.0, 0.12777365741134986, 0.0, 0.2874935496978787, 0.0, 0.0, 0.021877890033203812, 0.1316957530661763, 0.0, 1.0462327541742331, 0.24642978428043782, 0.0, 1.292534939963643e-5, 0.04966212026978902, 0.16767073337455046, 0.24586075312633993, 0.7749426824526595, 0.2192927197338787, 0.0, 0.15373812475086615, 0.1693253879539043, 1.1992945978003244, 0.0, 0.19769335810835964, 0.0, 0.2843031573913307, 0.2653563328642114, 0.6319651047837591, 0.0, 0.0, 0.2886502960323224, 0.2007500567698334, 0.0, 0.0, 0.0, 0.0, 0.4490517136878312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43431608561880214, 0.0, 0.0, 0.0, 0.29096240214176294, 0.0, 0.0, 0.24728201213730056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199315833820732, 0.40813133046287003, 0.25266186539111524, 0.0908889085249469, 0.0, 0.0, 0.45688115062815576, 0.11100101499363633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264115832549351, 0.6164930072930471, 0.0, 0.0, 0.44347420874850846, 0.0, 0.17884284240125642, 0.0, 0.2888836731929794, 0.21018531617189648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3429810739029393, 0.02002166425453684, 0.021961075245274804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.557136258905774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36191890674012556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12978916081088554, 0.0, 0.33079766328323545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464300021869425, 0.0, 0.0, 0.0, 0.0, 0.5063973085557268, 0.26737229244864336, 0.08619179411886842, 0.0, 0.0, 0.0, 0.49896059675156373, 0.0, 0.9000423796847855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6355437645077721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3962962286854009, 0.0, 0.0, 0.33976760898340913, 0.0, 0.0, 0.478819001240275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 42), 42)),)

